{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f792151",
   "metadata": {},
   "source": [
    "# ğŸ“œâ€¯Cellâ€¯1 â€“ Algorithm Overview & Pseudocode\n",
    "\n",
    "**Flatâ€¯TTâ€‘KNN with Stayâ€‘Prior & Dynamic Lookâ€‘Ahead (Humobâ€¯2025)**  \n",
    "\n",
    "**Training**  \n",
    "1. **Load & split**  âœ daysâ€¯1â€‘60Â +â€¯Ïâ€¯Â·â€¯unmasked(61â€‘75) â‡¢ **train**, rest â‡¢ **val**  \n",
    "2. **Build perâ€‘user statistics**  \n",
    "   * `stay_p`Â Â =â€¯P(locâ‚œâ‚Šâ‚â€¯=â€¯locâ‚œ)  \n",
    "   * `median_gap`Â =â€¯median #segments between successive *moves*  \n",
    "3. **Dynamic lookâ€‘ahead** `Máµ¢â€¯=â€¯clip(median_gap,â€¯1,â€¯6)`  \n",
    "4. **Build transition table** `(segment, cur_loc) â†’ Counter(next_loc)`  \n",
    "   * Filter locations visited `<â€¯Ï„` times  \n",
    "   * Keep transitions with `gap â‰¤ Máµ¢`\n",
    "\n",
    "**Prediction (per user)**  \n",
    "1. Let current `(d,t, locâ‚€)`  \n",
    "2. Look ahead `1â€¦Máµ¢` segments; collect candidate next locations  \n",
    "3. **Score** each candidate  \n",
    "   *   `norm_dist`Â Â Â (lowerÂ better)  \n",
    "   *   `norm_freq`Â Â Â (higherÂ better)  \n",
    "4. Lowest blended score wins (ties â†” topâ€‘K)  \n",
    "5. **Stay bias**: If predicted â‰  locâ‚€, choose `locâ‚€` instead when  \n",
    "   `Î»Â·stay_p > 1â€¯âˆ’â€¯stay_p`\n",
    "\n",
    "**Evaluation**  \n",
    "* Sequential prediction across validation set  \n",
    "* Perâ€‘user **GeoBLEU** & **DTW**, then macroâ€‘average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e7ef4",
   "metadata": {},
   "source": [
    "# ğŸ› ï¸â€¯Cellâ€¯2 â€“ Install external metrics package\n",
    "!pip install -q git+https://github.com/yahoojapan/geobleu.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d04c22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Globals ready.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“šâ€¯Cellâ€¯3 â€“ Imports & Global Constants\n",
    "import numpy as np, pandas as pd, random, seaborn as sns, matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from geobleu import calc_geobleu_single, calc_dtw_single\n",
    "import warnings, os, json, math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- reproducibility ---\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# --- Dataset parameters (HumobÂ 2025) ---\n",
    "DATA_DIR       = \"data\"      # change if needed\n",
    "MASK_VALUE     = 999\n",
    "COLUMNS        = [\"uid\", \"d\", \"t\", \"x\", \"y\"]\n",
    "DTYPES         = {\"uid\": \"int32\",\"d\": \"int8\",\"t\": \"int8\",\"x\": \"int16\",\"y\": \"int16\"}\n",
    "DAY_TRAIN_MAX  = 60\n",
    "DAY_VAL_MIN    = 61\n",
    "DAY_VAL_MAX    = 75\n",
    "\n",
    "# --- Base hyperâ€‘params ---\n",
    "BASE_CFG = dict(\n",
    "    DELTA       = 30,     # minutes per segment\n",
    "    TAU         = 5,      # min visits per location\n",
    "    M_DEFAULT   = 2,      # fallback lookâ€‘ahead\n",
    "    K           = 2,      # KNN\n",
    "    FREQ_W      = 0.5,    # frequency weight in score\n",
    "    STAY_W      = 0.4,    # Î» for stay bias\n",
    "    TRAIN_FRAC  = 0.7     # Ï  (train share in daysÂ 61â€‘75)\n",
    ")\n",
    "\n",
    "print(\"Globals ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§â€¯Cellâ€¯4 â€“ Distance & Timeâ€‘Segment Utilities\n",
    "def euclidean(a, b):\n",
    "    return math.hypot(a[0]-b[0], a[1]-b[1])\n",
    "\n",
    "def manhattan(a, b):\n",
    "    return abs(a[0]-b[0]) + abs(a[1]-b[1])\n",
    "\n",
    "def chebyshev(a, b):\n",
    "    return max(abs(a[0]-b[0]), abs(a[1]-b[1]))\n",
    "\n",
    "def calc_dist(a, b, typ='euclidean'):\n",
    "    return {'euclidean': euclidean,\n",
    "            'manhattan': manhattan,\n",
    "            'chebyshev': chebyshev}[typ](a, b)\n",
    "\n",
    "def to_flat_segment(day, t, delta=30):\n",
    "    \"\"\"Return global segment index since dayâ€‘0 00:00\"\"\"\n",
    "    segs_per_day = (24*60) // delta\n",
    "    return day*segs_per_day + (t*60)//delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e6f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ˆâ€¯Cellâ€¯5 â€“ Perâ€‘User Statistics: stay_p and median_gap\n",
    "def compute_user_stats(traj, delta):\n",
    "    \"\"\"\n",
    "    traj : list[((x,y),(d,t))] chronological\n",
    "    â†’ (stay_probability, median_gap_segments)\n",
    "    \"\"\"\n",
    "    if len(traj) < 2:\n",
    "        return 0.0, 1\n",
    "    traj = sorted(traj, key=lambda z: (z[1][0], z[1][1]))\n",
    "    stay, gaps = 0, []\n",
    "    last_seg = to_flat_segment(*traj[0][1], delta)\n",
    "    last_loc = traj[0][0]\n",
    "    for loc, (d, t) in traj[1:]:\n",
    "        seg = to_flat_segment(d, t, delta)\n",
    "        gap = seg - last_seg\n",
    "        if gap <= 0:          # duplicate or unordered\n",
    "            continue\n",
    "        if loc == last_loc:\n",
    "            stay += 1\n",
    "        else:\n",
    "            gaps.append(gap)\n",
    "            last_loc = loc\n",
    "        last_seg = seg\n",
    "    median_gap = int(np.median(gaps)) if gaps else 1\n",
    "    return stay / max(len(traj)-1,1), median_gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—ï¸â€¯Cellâ€¯6 â€“ Transitionâ€‘Table Builder (accepts userâ€‘specific M)\n",
    "def build_flat_TT_index(trajectory, tau=5, delta=30, M=2):\n",
    "    \"\"\"\n",
    "    trajectory : list[(d, t, x, y)]\n",
    "    returns    : TT_index, TT_freq  (defaultdict structures)\n",
    "    \"\"\"\n",
    "    loc_counts = Counter((x,y) for _,_,x,y in trajectory)\n",
    "    traj_filt  = [(d,t,x,y) for d,t,x,y in trajectory if loc_counts[(x,y)] >= tau]\n",
    "    TT_idx = defaultdict(lambda: defaultdict(list))\n",
    "    TT_freq= defaultdict(lambda: defaultdict(Counter))\n",
    "    seg_traj = [(to_flat_segment(d,t,delta),(x,y)) for d,t,x,y in traj_filt]\n",
    "    seg_traj.sort()\n",
    "    for i in range(len(seg_traj)-1):\n",
    "        seg1, loc1 = seg_traj[i]\n",
    "        seg2, loc2 = seg_traj[i+1]\n",
    "        if 0 < seg2-seg1 <= M:\n",
    "            TT_idx[seg1][loc1].append(loc2)\n",
    "            TT_freq[seg1][loc1][loc2] += 1\n",
    "    return TT_idx, TT_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤–â€¯Cellâ€¯7 â€“ FlatTTKNNModel++  (stay prior + dynamic lookâ€‘ahead)\n",
    "class FlatTTKNNModel:\n",
    "    def __init__(self,\n",
    "                 tau           = BASE_CFG['TAU'],\n",
    "                 delta         = BASE_CFG['DELTA'],\n",
    "                 M_default     = BASE_CFG['M_DEFAULT'],\n",
    "                 K             = BASE_CFG['K'],\n",
    "                 distance_type = 'euclidean',\n",
    "                 freq_weight   = BASE_CFG['FREQ_W'],\n",
    "                 stay_weight   = BASE_CFG['STAY_W']):\n",
    "        self.tau, self.delta = tau, delta\n",
    "        self.M_default, self.K = M_default, K\n",
    "        self.distance_type = distance_type\n",
    "        self.freq_weight   = freq_weight\n",
    "        self.stay_weight   = stay_weight\n",
    "        self.index, self.freq_index = {}, {}\n",
    "        self.user_M, self.user_stay_p = {}, {}\n",
    "\n",
    "    # ---------- fit ----------\n",
    "    def fit(self, user_trajs):\n",
    "        for uid, traj in tqdm(user_trajs.items(), desc=\"Build indices\", leave=False):\n",
    "            stay_p, med_gap = compute_user_stats(traj, self.delta)\n",
    "            self.user_stay_p[uid] = stay_p\n",
    "            self.user_M[uid]      = int(np.clip(med_gap, 1, 6))\n",
    "            formatted = [(d,t,x,y) for (x,y),(d,t) in traj]\n",
    "            if formatted:\n",
    "                idx,freq = build_flat_TT_index(formatted,\n",
    "                                               tau   = self.tau,\n",
    "                                               delta = self.delta,\n",
    "                                               M     = self.user_M[uid])\n",
    "                self.index[uid], self.freq_index[uid] = idx, freq\n",
    "\n",
    "    # ---------- core predictor ----------\n",
    "    def _predict_knn(self, uid, d, t, loc):\n",
    "        \"\"\"plain TTâ€‘KNN w/out stay bias\"\"\"\n",
    "        if uid not in self.index:\n",
    "            return loc\n",
    "        M = self.user_M.get(uid, self.M_default)\n",
    "        curr_seg = to_flat_segment(d,t,self.delta)\n",
    "        cand, cand_freq = [], []\n",
    "        for o in range(1, M+1):\n",
    "            seg = curr_seg + o\n",
    "            if seg in self.index[uid] and loc in self.index[uid][seg]:\n",
    "                nxts = self.index[uid][seg][loc]\n",
    "                freqs= [self.freq_index[uid][seg][loc][n] for n in nxts]\n",
    "                cand.extend(nxts); cand_freq.extend(freqs)\n",
    "        if not cand:\n",
    "            return loc\n",
    "        uniq = {}\n",
    "        for l,f in zip(cand,cand_freq):\n",
    "            uniq[l] = uniq.get(l,0)+f\n",
    "        dist_vals = [calc_dist(loc,l,self.distance_type) for l in uniq]\n",
    "        min_d,max_d = min(dist_vals), max(dist_vals)\n",
    "        rng = max(max_d-min_d,1e-6)\n",
    "        best = sorted(\n",
    "            (( ( (calc_dist(loc,l,self.distance_type)-min_d)/rng ) /\n",
    "               ( (uniq[l]/max(uniq.values()))**self.freq_weight + 1e-6 ),\n",
    "               l) for l in uniq),\n",
    "            key=lambda z:z[0])[:self.K]\n",
    "        for _,l in best:\n",
    "            if l!=loc: return l\n",
    "        return loc\n",
    "\n",
    "    # ---------- public predict ----------\n",
    "    def predict(self, uid, d, t, loc):\n",
    "        raw_pred = self._predict_knn(uid,d,t,loc)\n",
    "        stay_p   = self.user_stay_p.get(uid,0)\n",
    "        if raw_pred!=loc and (self.stay_weight*stay_p > (1-stay_p)):\n",
    "            return loc\n",
    "        return raw_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38932732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—‚ï¸â€¯Cellâ€¯8 â€“ Dummy Baseline Predictors\n",
    "class DummyPredictor:\n",
    "    def __init__(self, strategy='fixed', fixed_loc=(0,0)):\n",
    "        self.strategy, self.fixed_loc = strategy, fixed_loc\n",
    "        self.common = {}\n",
    "    def fit(self, user_trajs):\n",
    "        if self.strategy=='random':\n",
    "            for u,tr in user_trajs.items():\n",
    "                locs=[l for l,_ in tr]\n",
    "                cnt=Counter(locs)\n",
    "                self.common[u]=[l for l,_ in cnt.most_common(5)] or [locs[0]]\n",
    "    def predict(self, uid,d,t,loc):\n",
    "        if self.strategy=='fixed': return self.fixed_loc\n",
    "        if self.strategy=='last' : return loc\n",
    "        if self.strategy=='random':\n",
    "            return random.choice(self.common.get(uid,[loc]))\n",
    "        return loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec74907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‚â€¯Cellâ€¯9 â€“ Data Loading & Splitting (trainÂ /Â val)\n",
    "def load_and_split(city, train_frac=BASE_CFG['TRAIN_FRAC'], seed=42):\n",
    "    path = f\"{DATA_DIR}/city_{city}_challengedata.csv\"\n",
    "    train_early, tail = [], []\n",
    "    for chunk in tqdm(pd.read_csv(path,usecols=COLUMNS,dtype=DTYPES,chunksize=500_000)):\n",
    "        te = chunk[(chunk.d<=DAY_TRAIN_MAX)&(chunk.x!=MASK_VALUE)]\n",
    "        tl = chunk[(chunk.d>=DAY_VAL_MIN)&(chunk.d<=DAY_VAL_MAX)&(chunk.x!=MASK_VALUE)]\n",
    "        if not te.empty: train_early.append(te)\n",
    "        if not tl.empty: tail.append(tl)\n",
    "    train_df = pd.concat(train_early) if train_early else pd.DataFrame(columns=COLUMNS)\n",
    "    tail_df  = pd.concat(tail) if tail else pd.DataFrame(columns=COLUMNS)\n",
    "    # split tail by users\n",
    "    np.random.seed(seed)\n",
    "    users = tail_df.uid.unique()\n",
    "    n_tr  = int(len(users)*train_frac)\n",
    "    tr_users = set(np.random.choice(users, n_tr, replace=False))\n",
    "    train_tail = tail_df[tail_df.uid.isin(tr_users)]\n",
    "    val_df     = tail_df[~tail_df.uid.isin(tr_users)]\n",
    "    full_train = pd.concat([train_df, train_tail], ignore_index=True)\n",
    "    print(f\"Loaded City {city}: train={len(full_train):,}, val={len(val_df):,}\")\n",
    "    return full_train, val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„â€¯Cellâ€¯10 â€“ Helper: dataframe âœ user trajectories dictionary\n",
    "def df_to_trajs(df):\n",
    "    trajs = defaultdict(list)\n",
    "    df_s  = df.sort_values(['uid','d','t'])\n",
    "    for uid,grp in df_s.groupby('uid'):\n",
    "        locs = list(zip(grp.x,grp.y))\n",
    "        ts   = list(zip(grp.d,grp.t))\n",
    "        trajs[uid] = list(zip(locs, ts))\n",
    "    return dict(trajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d29563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”®â€¯Cellâ€¯11 â€“ Sequential Prediction Loop\n",
    "def run_prediction(model, val_df, hist_trajs):\n",
    "    val_sorted = val_df.sort_values(['uid','d','t']).copy()\n",
    "    out = val_sorted[['uid','d','t','x','y']].copy()\n",
    "    out['x_pred']=np.nan; out['y_pred']=np.nan\n",
    "    for uid,grp in tqdm(val_sorted.groupby('uid'), desc=\"Predict\"):\n",
    "        history = list(hist_trajs.get(uid, []))\n",
    "        preds=[]\n",
    "        for _,row in grp.iterrows():\n",
    "            d,t,row_loc = row.d,row.t,(row.x,row.y)\n",
    "            last_loc = history[-1][0] if history else row_loc\n",
    "            pred = model.predict(uid,d,t,last_loc)\n",
    "            preds.append(pred)\n",
    "            history.append((pred,(d,t)))         # update with prediction\n",
    "        idx = grp.index\n",
    "        out.loc[idx,'x_pred']=[p[0] for p in preds]\n",
    "        out.loc[idx,'y_pred']=[p[1] for p in preds]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“â€¯Cellâ€¯12 â€“ Metric Calculator (GeoBLEU & DTW)\n",
    "def eval_metrics(pred_df, val_df):\n",
    "    merged = pred_df.merge(\n",
    "        val_df.rename(columns={'x':'x_gt','y':'y_gt'}),\n",
    "        on=['uid','d','t'], how='inner')\n",
    "    if merged.empty:\n",
    "        return dict(geobleu=0., dtw=float('inf'))\n",
    "    met=[]\n",
    "    for uid,g in merged.groupby('uid'):\n",
    "        if len(g)<2: continue\n",
    "        gt  = [(int(r.d),int(r.t),int(r.x_gt),int(r.y_gt)) for _,r in g.sort_values(['d','t']).iterrows()]\n",
    "        pr  = [(int(r.d),int(r.t),int(r.x_pred),int(r.y_pred)) for _,r in g.sort_values(['d','t']).iterrows()]\n",
    "        try:\n",
    "            met.append((calc_geobleu_single(pr,gt), calc_dtw_single(pr,gt)))\n",
    "        except Exception: pass\n",
    "    if not met: return dict(geobleu=0., dtw=float('inf'))\n",
    "    arr=np.array(met)\n",
    "    return dict(geobleu=arr[:,0].mean().round(5), dtw=arr[:,1].mean().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”â€¯Cellâ€¯13 â€“ Hyperâ€‘parameter Grid Search (optional narrow grid)\n",
    "GRID = [\n",
    "    dict(distance_type='euclidean', freq_weight=0.5, stay_weight=0.4),\n",
    "    dict(distance_type='manhattan', freq_weight=1.0, stay_weight=0.4),\n",
    "    dict(distance_type='chebyshev',  freq_weight=0.5, stay_weight=0.6)\n",
    "]\n",
    "def run_search(city):\n",
    "    tr_df, val_df = load_and_split(city)\n",
    "    if tr_df.empty or val_df.empty: return None\n",
    "    tr_trajs = df_to_trajs(tr_df)\n",
    "    best, best_score = None, -1\n",
    "    for i,cfg in enumerate(GRID,1):\n",
    "        print(f\"\\nConfig {i}/{len(GRID)} âœ\", json.dumps(cfg))\n",
    "        model = FlatTTKNNModel(**cfg)\n",
    "        model.fit(tr_trajs)\n",
    "        pred_df = run_prediction(model, val_df, tr_trajs)\n",
    "        scores = eval_metrics(pred_df, val_df)\n",
    "        print(\"  GeoBLEU\",scores['geobleu'],\"DTW\",scores['dtw'])\n",
    "        if scores['geobleu']>best_score:\n",
    "            best_score,best = scores['geobleu'], dict(cfg, **scores)\n",
    "    print(\"\\nğŸ† Best:\", best)\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== City F ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d54c01fb524b718d1f5b6c6ea7e941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded City F: train=471, val=29\n",
      "\n",
      "Config 1/3 âœ {\"distance_type\": \"euclidean\", \"freq_weight\": 0.5, \"stay_weight\": 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625e4802f4464a1d8b50b4271feab773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build indices:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daf8f7a39b4466e96f8ba8ce8e7d1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GeoBLEU 0.0006 DTW 27.09\n",
      "\n",
      "Config 2/3 âœ {\"distance_type\": \"manhattan\", \"freq_weight\": 1.0, \"stay_weight\": 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b165d82477da40d09e73e0f139274d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build indices:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1841e7e7146646479199735410cf0acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GeoBLEU 0.0006 DTW 27.09\n",
      "\n",
      "Config 3/3 âœ {\"distance_type\": \"chebyshev\", \"freq_weight\": 0.5, \"stay_weight\": 0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bae6e471e8c44319d23f45a8bd59930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build indices:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa0f999a21444489c665c381a4fb1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GeoBLEU 0.0006 DTW 27.09\n",
      "\n",
      "ğŸ† Best: {'distance_type': 'euclidean', 'freq_weight': 0.5, 'stay_weight': 0, 'geobleu': 0.0006, 'dtw': 27.09}\n",
      "\n",
      "ğŸ‰Â DONE\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€â€¯Cellâ€¯14 â€“ Execute for target city/cities\n",
    "CITIES = [\"F\"]           # change / extend\n",
    "results = {}\n",
    "for city in CITIES:\n",
    "    print(f\"\\n=== City {city} ===\")\n",
    "    results[city] = run_search(city)\n",
    "print(\"\\nğŸ‰Â DONE\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
