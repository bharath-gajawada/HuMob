{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb573507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:18.774392Z",
     "iopub.status.busy": "2025-06-12T12:32:18.774107Z",
     "iopub.status.idle": "2025-06-12T12:32:27.747587Z",
     "shell.execute_reply": "2025-06-12T12:32:27.746181Z",
     "shell.execute_reply.started": "2025-06-12T12:32:18.774370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for geobleu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/yahoojapan/geobleu.git tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1edce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:27.750327Z",
     "iopub.status.busy": "2025-06-12T12:32:27.749946Z",
     "iopub.status.idle": "2025-06-12T12:32:28.922867Z",
     "shell.execute_reply": "2025-06-12T12:32:28.922039Z",
     "shell.execute_reply.started": "2025-06-12T12:32:27.750290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from geobleu import calc_geobleu_single\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Ensure floats print with 5 decimals\n",
    "pd.set_option(\"display.float_format\", \"{:.5f}\".format)\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = \"/kaggle/input/humob-data/15313913\"\n",
    "# CITIES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "CITIES = [\"B\", \"C\", \"D\"]\n",
    "COLUMNS = [\"uid\", \"d\", \"t\", \"x\", \"y\"]\n",
    "DTYPES = {\n",
    "    \"uid\": \"int32\",\n",
    "    \"d\": \"int8\",\n",
    "    \"t\": \"int8\",\n",
    "    \"x\": \"int16\",\n",
    "    \"y\": \"int16\",\n",
    "}\n",
    "TRAIN_DAY_MAX = 60\n",
    "TEST_DAY_MIN = 61\n",
    "MASK_VALUE = 999\n",
    "CHUNK_SIZE = 500_000  # adjust as needed for memory/time\n",
    "\n",
    "# Checkpoint directory\n",
    "CHECKPOINT_DIR = \"/home/bharath/Documents/4-1/BTP/HuMob/checkpoints\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducible sampling\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ff35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(data, filename, checkpoint_type=\"results\"):\n",
    "    \"\"\"\n",
    "    Save checkpoint data to disk.\n",
    "    \n",
    "    Args:\n",
    "        data: Data to save (dict, DataFrame, etc.)\n",
    "        filename: Name of the checkpoint file\n",
    "        checkpoint_type: Type of checkpoint ('results', 'aggregates', 'coverage')\n",
    "    \"\"\"\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"{checkpoint_type}_{filename}\")\n",
    "    \n",
    "    try:\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            data.to_pickle(f\"{checkpoint_path}.pkl\")\n",
    "        else:\n",
    "            with open(f\"{checkpoint_path}.json\", 'w') as f:\n",
    "                json.dump(data, f, indent=2, default=str)\n",
    "        \n",
    "        # Also save metadata\n",
    "        metadata = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': checkpoint_type,\n",
    "            'filename': filename,\n",
    "            'data_type': type(data).__name__\n",
    "        }\n",
    "        with open(f\"{checkpoint_path}_meta.json\", 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "            \n",
    "        print(f\"✓ Checkpoint saved: {checkpoint_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to save checkpoint {checkpoint_path}: {e}\")\n",
    "\n",
    "def load_checkpoint(filename, checkpoint_type=\"results\"):\n",
    "    \"\"\"\n",
    "    Load checkpoint data from disk.\n",
    "    \n",
    "    Args:\n",
    "        filename: Name of the checkpoint file\n",
    "        checkpoint_type: Type of checkpoint ('results', 'aggregates', 'coverage')\n",
    "    \n",
    "    Returns:\n",
    "        Loaded data or None if not found\n",
    "    \"\"\"\n",
    "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"{checkpoint_type}_{filename}\")\n",
    "    \n",
    "    # Try loading pickle first (for DataFrames)\n",
    "    if os.path.exists(f\"{checkpoint_path}.pkl\"):\n",
    "        try:\n",
    "            data = pd.read_pickle(f\"{checkpoint_path}.pkl\")\n",
    "            print(f\"✓ Checkpoint loaded: {checkpoint_path}.pkl\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load pickle checkpoint: {e}\")\n",
    "    \n",
    "    # Try loading JSON\n",
    "    if os.path.exists(f\"{checkpoint_path}.json\"):\n",
    "        try:\n",
    "            with open(f\"{checkpoint_path}.json\", 'r') as f:\n",
    "                data = json.load(f)\n",
    "            print(f\"✓ Checkpoint loaded: {checkpoint_path}.json\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to load JSON checkpoint: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def list_checkpoints():\n",
    "    \"\"\"List all available checkpoints.\"\"\"\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        print(\"No checkpoint directory found.\")\n",
    "        return\n",
    "    \n",
    "    checkpoints = {}\n",
    "    for file in os.listdir(CHECKPOINT_DIR):\n",
    "        if file.endswith('_meta.json'):\n",
    "            try:\n",
    "                with open(os.path.join(CHECKPOINT_DIR, file), 'r') as f:\n",
    "                    metadata = json.load(f)\n",
    "                checkpoints[file.replace('_meta.json', '')] = metadata\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(\"Available checkpoints:\")\n",
    "        for name, meta in sorted(checkpoints.items()):\n",
    "            print(f\"  {name}: {meta['type']} ({meta['timestamp']})\")\n",
    "    else:\n",
    "        print(\"No checkpoints found.\")\n",
    "\n",
    "def save_train_aggregates(city_code, aggregates):\n",
    "    \"\"\"Save training aggregates for a city.\"\"\"\n",
    "    data = {\n",
    "        'global_mean': aggregates[0],\n",
    "        'global_mode': aggregates[1],\n",
    "        'per_user_mean_df': aggregates[2],\n",
    "        'per_user_mode_df': aggregates[3],\n",
    "        'per_user_unigram_dict': aggregates[4],\n",
    "        'per_user_bigram_dict': aggregates[5]\n",
    "    }\n",
    "    \n",
    "    # Save DataFrames separately\n",
    "    save_checkpoint(data['per_user_mean_df'], f\"city_{city_code}_mean_df\", \"aggregates\")\n",
    "    save_checkpoint(data['per_user_mode_df'], f\"city_{city_code}_mode_df\", \"aggregates\")\n",
    "    \n",
    "    # Save other data as JSON (convert complex objects to serializable format)\n",
    "    json_data = {\n",
    "        'global_mean': data['global_mean'],\n",
    "        'global_mode': data['global_mode'],\n",
    "        'per_user_unigram_dict': {str(k): dict(v) for k, v in data['per_user_unigram_dict'].items()},\n",
    "        'per_user_bigram_dict': {str(k): {str(bigram): count for bigram, count in v.items()} \n",
    "                                for k, v in data['per_user_bigram_dict'].items()}\n",
    "    }\n",
    "    \n",
    "    save_checkpoint(json_data, f\"city_{city_code}_aggregates\", \"aggregates\")\n",
    "\n",
    "def load_train_aggregates(city_code):\n",
    "    \"\"\"Load training aggregates for a city.\"\"\"\n",
    "    # Load JSON data\n",
    "    json_data = load_checkpoint(f\"city_{city_code}_aggregates\", \"aggregates\")\n",
    "    if json_data is None:\n",
    "        return None\n",
    "    \n",
    "    # Load DataFrames\n",
    "    per_user_mean_df = load_checkpoint(f\"city_{city_code}_mean_df\", \"aggregates\")\n",
    "    per_user_mode_df = load_checkpoint(f\"city_{city_code}_mode_df\", \"aggregates\")\n",
    "    \n",
    "    if per_user_mean_df is None or per_user_mode_df is None:\n",
    "        return None\n",
    "    \n",
    "    # Reconstruct complex objects\n",
    "    per_user_unigram_dict = {\n",
    "        int(k): Counter({eval(coord): count for coord, count in v.items()}) \n",
    "        for k, v in json_data['per_user_unigram_dict'].items()\n",
    "    }\n",
    "    \n",
    "    per_user_bigram_dict = {\n",
    "        int(k): Counter({eval(bigram): count for bigram, count in v.items()}) \n",
    "        for k, v in json_data['per_user_bigram_dict'].items()\n",
    "    }\n",
    "    \n",
    "    return (\n",
    "        tuple(json_data['global_mean']),\n",
    "        tuple(json_data['global_mode']),\n",
    "        per_user_mean_df,\n",
    "        per_user_mode_df,\n",
    "        per_user_unigram_dict,\n",
    "        per_user_bigram_dict\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8fb1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:28.924208Z",
     "iopub.status.busy": "2025-06-12T12:32:28.923725Z",
     "iopub.status.idle": "2025-06-12T12:32:28.935201Z",
     "shell.execute_reply": "2025-06-12T12:32:28.934250Z",
     "shell.execute_reply.started": "2025-06-12T12:32:28.924173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def _geobleu_for_group(group):\n",
    "    \"\"\"\n",
    "    Given a DataFrame for one uid (with columns 'd','t','x_pred','y_pred','x_gt','y_gt'),\n",
    "    compute and return its GEO-BLEU score.\n",
    "    \"\"\"\n",
    "    pred_seq = list(zip(group['d'], group['t'], group['x_pred'], group['y_pred']))\n",
    "    true_seq = list(zip(group['d'], group['t'], group['x_gt'], group['y_gt']))\n",
    "    return calc_geobleu_single(pred_seq, true_seq)\n",
    "\n",
    "def evaluate_geobleu_parallel(pred_df: pd.DataFrame, gt_df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    - pred_df:  DataFrame with columns ['uid','d','t','x_pred','y_pred']\n",
    "    - gt_df:    DataFrame with columns ['uid','d','t','x_gt','y_gt']\n",
    "\n",
    "    Merges on ['uid','d','t'], then uses multiprocessing + tqdm to compute\n",
    "    GEO-BLEU per user in parallel. Returns the average GEO-BLEU over all users.\n",
    "    \"\"\"\n",
    "    merged = pd.merge(pred_df, gt_df, on=['uid', 'd', 't'], how='inner')\n",
    "    if merged.empty:\n",
    "        return 0.0\n",
    "\n",
    "    # Rename ground-truth x,y for readability\n",
    "    merged = merged.rename(columns={'x': 'x_gt', 'y': 'y_gt'})\n",
    "\n",
    "    # Split into list of DataFrames by uid\n",
    "    grouped = [grp for _, grp in merged.groupby('uid')]\n",
    "    num_users = len(grouped)\n",
    "    if num_users == 0:\n",
    "        return 0.0\n",
    "\n",
    "    print(f\"    ▶ Evaluating GEO-BLEU on {num_users} users...\")\n",
    "\n",
    "    # Use imap_unordered + tqdm for a progress bar\n",
    "    with mp.Pool(processes=max(1, mp.cpu_count() - 1)) as pool:\n",
    "        results = []\n",
    "        for score in tqdm(pool.imap_unordered(_geobleu_for_group, grouped),\n",
    "                          total=num_users,\n",
    "                          desc=\"      GEO-BLEU\"):\n",
    "            results.append(score)\n",
    "    return float(np.mean(results)) if results else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "150d62d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:28.938015Z",
     "iopub.status.busy": "2025-06-12T12:32:28.937659Z",
     "iopub.status.idle": "2025-06-12T12:32:28.973751Z",
     "shell.execute_reply": "2025-06-12T12:32:28.972881Z",
     "shell.execute_reply.started": "2025-06-12T12:32:28.937988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_train_aggregates(city_code: str):\n",
    "    \"\"\"\n",
    "    Reads city_{city_code}_challengedata.csv in chunks (days 1–60) and computes:\n",
    "      - global mean (gm_x, gm_y)\n",
    "      - global mode (gmod_x, gmod_y)\n",
    "      - per_user_mean_df: DataFrame indexed by uid, columns ['x','y']\n",
    "      - per_user_mode_df: DataFrame indexed by uid, columns ['x','y']\n",
    "      - per_user_unigram_dict: Dictionary uid → Counter((x,y) → frequency)\n",
    "      - per_user_bigram_dict: Dictionary uid → Counter(((x1,y1), (x2,y2)) → frequency)\n",
    "    \"\"\"\n",
    "    print(f\">>> Computing train aggregates for City {city_code} ...\")\n",
    "\n",
    "    # Accumulators for global mean\n",
    "    total_x = 0\n",
    "    total_y = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # 200×200 array for global mode counts\n",
    "    global_mode_counts = np.zeros((200, 200), dtype=np.int64)\n",
    "\n",
    "    # Per-user accumulators\n",
    "    per_user_sums = defaultdict(lambda: [0, 0, 0])   # uid → [sum_x, sum_y, count]\n",
    "    per_user_modes = defaultdict(Counter)           # uid → Counter((x,y) → freq)\n",
    "    per_user_unigrams = defaultdict(Counter)        # uid → Counter((x,y) → freq) for unigram model\n",
    "    per_user_bigrams = defaultdict(Counter)         # uid → Counter(((x1,y1), (x2,y2)) → freq)\n",
    "\n",
    "    path = os.path.join(DATA_DIR, f\"city_{city_code}_challengedata.csv\")\n",
    "\n",
    "    # Read the file in chunks\n",
    "    for chunk in tqdm(pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE),\n",
    "                      desc=f\"Loading chunks (City {city_code})\"):\n",
    "        # Filter training portion (days 1–60)\n",
    "        train_chunk = chunk[chunk[\"d\"] <= TRAIN_DAY_MAX]\n",
    "        if train_chunk.empty:\n",
    "            continue\n",
    "\n",
    "        xs = train_chunk[\"x\"].to_numpy(dtype=np.int64)\n",
    "        ys = train_chunk[\"y\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "        # Update global mean accumulators\n",
    "        total_x += xs.sum()\n",
    "        total_y += ys.sum()\n",
    "        total_count += len(train_chunk)\n",
    "\n",
    "        # Update global mode counts (zero-based indexing)\n",
    "        xi = xs - 1\n",
    "        yi = ys - 1\n",
    "        np.add.at(global_mode_counts, (xi, yi), 1)\n",
    "\n",
    "        # Update per-user sums, modes, unigrams, and bigrams\n",
    "        for uid, sub in train_chunk.groupby(\"uid\"):\n",
    "            arr_x = sub[\"x\"].to_numpy(dtype=np.int64)\n",
    "            arr_y = sub[\"y\"].to_numpy(dtype=np.int64)\n",
    "            per_user_sums[uid][0] += arr_x.sum()\n",
    "            per_user_sums[uid][1] += arr_y.sum()\n",
    "            per_user_sums[uid][2] += len(sub)\n",
    "\n",
    "            coords = list(zip(sub[\"x\"], sub[\"y\"]))\n",
    "            per_user_modes[uid].update(coords)\n",
    "            per_user_unigrams[uid].update(coords)\n",
    "            \n",
    "            # Build bigrams within each user's trajectory (ordered by d, t)\n",
    "            user_sub = sub.sort_values(['d', 't'])\n",
    "            user_coords = list(zip(user_sub[\"x\"], user_sub[\"y\"]))\n",
    "            if len(user_coords) > 1:\n",
    "                bigrams = [(user_coords[i], user_coords[i+1]) for i in range(len(user_coords)-1)]\n",
    "                per_user_bigrams[uid].update(bigrams)\n",
    "\n",
    "        del train_chunk  # free memory\n",
    "\n",
    "    # Compute global mean (rounded)\n",
    "    gm_x = int(round(total_x / total_count))\n",
    "    gm_y = int(round(total_y / total_count))\n",
    "\n",
    "    # Compute global mode from the 200×200 matrix\n",
    "    flat_idx = np.argmax(global_mode_counts)\n",
    "    gmod_x = (flat_idx // 200) + 1\n",
    "    gmod_y = (flat_idx % 200) + 1\n",
    "\n",
    "    # Build per-user mean DataFrame\n",
    "    user_mean_records = []\n",
    "    for uid, (sx, sy, cnt) in per_user_sums.items():\n",
    "        user_mean_records.append((uid, int(round(sx / cnt)), int(round(sy / cnt))))\n",
    "    per_user_mean_df = (\n",
    "        pd.DataFrame(user_mean_records, columns=[\"uid\", \"x\", \"y\"])\n",
    "          .set_index(\"uid\")\n",
    "          .astype(\"int16\")\n",
    "    )\n",
    "\n",
    "    # Build per-user mode DataFrame\n",
    "    user_mode_records = []\n",
    "    for uid, counter in per_user_modes.items():\n",
    "        (mx, my), _ = counter.most_common(1)[0]\n",
    "        user_mode_records.append((uid, int(mx), int(my)))\n",
    "    per_user_mode_df = (\n",
    "        pd.DataFrame(user_mode_records, columns=[\"uid\", \"x\", \"y\"])\n",
    "          .set_index(\"uid\")\n",
    "          .astype(\"int16\")\n",
    "    )\n",
    "\n",
    "    print(f\"Train aggregates done: GM=({gm_x},{gm_y}), GMODE=({gmod_x},{gmod_y}), \"\n",
    "          f\"{len(per_user_mean_df)} users' means, {len(per_user_mode_df)} users' modes, \"\n",
    "          f\"{len(per_user_unigrams)} users' unigrams, {len(per_user_bigrams)} users' bigrams.\")\n",
    "    return (gm_x, gm_y), (gmod_x, gmod_y), per_user_mean_df, per_user_mode_df, dict(per_user_unigrams), dict(per_user_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49898ad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:29.922314Z",
     "iopub.status.busy": "2025-06-12T12:32:29.921955Z",
     "iopub.status.idle": "2025-06-12T12:32:29.929417Z",
     "shell.execute_reply": "2025-06-12T12:32:29.928560Z",
     "shell.execute_reply.started": "2025-06-12T12:32:29.922289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_test_dataframe(city_code: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads city_{city_code}_challengedata.csv in chunks and collects only the rows\n",
    "    where d ≥ 61 and x,y != 999. Returns a DataFrame [uid,d,t,x,y].\n",
    "    \"\"\"\n",
    "    print(f\">>> Building test DataFrame for City {city_code} ...\")\n",
    "    path = os.path.join(DATA_DIR, f\"city_{city_code}_challengedata.csv\")\n",
    "    test_parts = []\n",
    "\n",
    "    for chunk in tqdm(pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE),\n",
    "                      desc=f\"Loading test chunks (City {city_code})\"):\n",
    "        mask = (chunk[\"d\"] >= TEST_DAY_MIN) & (chunk[\"x\"] != MASK_VALUE) & (chunk[\"y\"] != MASK_VALUE)\n",
    "        sub = chunk.loc[mask, [\"uid\", \"d\", \"t\", \"x\", \"y\"]]\n",
    "        if not sub.empty:\n",
    "            test_parts.append(sub.copy())\n",
    "        del chunk\n",
    "\n",
    "    if test_parts:\n",
    "        test_df = pd.concat(test_parts, ignore_index=True)\n",
    "    else:\n",
    "        test_df = pd.DataFrame(columns=[\"uid\", \"d\", \"t\", \"x\", \"y\"]).astype(DTYPES)\n",
    "\n",
    "    print(f\"Test DataFrame built: shape = {test_df.shape}\")\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c986ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:34.415192Z",
     "iopub.status.busy": "2025-06-12T12:32:34.414254Z",
     "iopub.status.idle": "2025-06-12T12:32:34.427231Z",
     "shell.execute_reply": "2025-06-12T12:32:34.426088Z",
     "shell.execute_reply.started": "2025-06-12T12:32:34.415148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_unigram_predictions(test_df: pd.DataFrame, per_user_unigram_dict: dict, \n",
    "                                gm_x: int, gm_y: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate predictions using unigram model for each user.\n",
    "    For each test point, sample from the user's location probability distribution.\n",
    "    Fallback to global mean for unseen users.\n",
    "    \"\"\"\n",
    "    print(f\"Generating Unigram predictions ...\")\n",
    "    \n",
    "    pred_unigram = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_unigram[\"x_pred\"] = 0\n",
    "    pred_unigram[\"y_pred\"] = 0\n",
    "    \n",
    "    # Group by user for efficient processing\n",
    "    for uid, group in tqdm(test_df.groupby(\"uid\"), desc=\"Unigram sampling\"):\n",
    "        if uid in per_user_unigram_dict:\n",
    "            # Get user's location distribution\n",
    "            location_counter = per_user_unigram_dict[uid]\n",
    "            locations = list(location_counter.keys())\n",
    "            frequencies = list(location_counter.values())\n",
    "            \n",
    "            # Convert frequencies to probabilities\n",
    "            total_freq = sum(frequencies)\n",
    "            probabilities = [f / total_freq for f in frequencies]\n",
    "            \n",
    "            # Sample locations for all test points of this user\n",
    "            num_samples = len(group)\n",
    "            sampled_indices = np.random.choice(len(locations), size=num_samples, p=probabilities)\n",
    "            sampled_locations = [locations[i] for i in sampled_indices]\n",
    "            \n",
    "            # Update predictions for this user\n",
    "            mask = pred_unigram[\"uid\"] == uid\n",
    "            pred_unigram.loc[mask, \"x_pred\"] = [loc[0] for loc in sampled_locations]\n",
    "            pred_unigram.loc[mask, \"y_pred\"] = [loc[1] for loc in sampled_locations]\n",
    "        else:\n",
    "            # Fallback to global mean for unseen users\n",
    "            mask = pred_unigram[\"uid\"] == uid\n",
    "            pred_unigram.loc[mask, \"x_pred\"] = gm_x\n",
    "            pred_unigram.loc[mask, \"y_pred\"] = gm_y\n",
    "    \n",
    "    return pred_unigram.astype({\"x_pred\": \"int16\", \"y_pred\": \"int16\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12a9ed5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:37.222197Z",
     "iopub.status.busy": "2025-06-12T12:32:37.221723Z",
     "iopub.status.idle": "2025-06-12T12:32:37.244241Z",
     "shell.execute_reply": "2025-06-12T12:32:37.243235Z",
     "shell.execute_reply.started": "2025-06-12T12:32:37.222160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def top_p_sampling(probabilities, top_p=0.7):\n",
    "    \"\"\"\n",
    "    Apply top-p (nucleus) sampling to probability distribution.\n",
    "    Returns indices and renormalized probabilities.\n",
    "    \"\"\"\n",
    "    # Sort probabilities in descending order\n",
    "    sorted_indices = np.argsort(probabilities)[::-1]\n",
    "    sorted_probs = np.array(probabilities)[sorted_indices]\n",
    "    \n",
    "    # Calculate cumulative probabilities\n",
    "    cumulative_probs = np.cumsum(sorted_probs)\n",
    "    \n",
    "    # Find cutoff point where cumulative probability exceeds top_p\n",
    "    cutoff_idx = np.searchsorted(cumulative_probs, top_p) + 1\n",
    "    cutoff_idx = min(cutoff_idx, len(sorted_probs))\n",
    "    \n",
    "    # Select top-p subset\n",
    "    selected_indices = sorted_indices[:cutoff_idx]\n",
    "    selected_probs = sorted_probs[:cutoff_idx]\n",
    "    \n",
    "    # Renormalize probabilities\n",
    "    selected_probs = selected_probs / selected_probs.sum()\n",
    "    \n",
    "    return selected_indices, selected_probs\n",
    "\n",
    "def generate_bigram_predictions(test_df: pd.DataFrame, per_user_bigram_dict: dict,\n",
    "                               per_user_unigram_dict: dict, gm_x: int, gm_y: int,\n",
    "                               top_p=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate predictions using bigram model for each user.\n",
    "    For each test point, use the previous location to predict the next location.\n",
    "    Apply top-p sampling if specified.\n",
    "    Fallback to unigram model if no bigram history, then to global mean.\n",
    "    \"\"\"\n",
    "    model_name = f\"Bigram Model (top_p={top_p})\" if top_p else \"Bigram Model\"\n",
    "    print(f\"Generating {model_name} predictions ...\")\n",
    "    \n",
    "    pred_bigram = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_bigram[\"x_pred\"] = 0\n",
    "    pred_bigram[\"y_pred\"] = 0\n",
    "    \n",
    "    # Process each user separately to maintain sequence order\n",
    "    for uid, group in tqdm(test_df.groupby(\"uid\"), desc=f\"{model_name} sampling\"):\n",
    "        # Sort test points by day and time to maintain sequence\n",
    "        user_test = group.sort_values(['d', 't']).copy()\n",
    "        \n",
    "        if uid in per_user_bigram_dict and per_user_bigram_dict[uid]:\n",
    "            bigram_counter = per_user_bigram_dict[uid]\n",
    "            \n",
    "            # Get the last location from training data as starting context\n",
    "            # Use the most frequent location as initial context\n",
    "            if uid in per_user_unigram_dict:\n",
    "                unigram_counter = per_user_unigram_dict[uid]\n",
    "                prev_location = unigram_counter.most_common(1)[0][0]\n",
    "            else:\n",
    "                prev_location = (gm_x, gm_y)\n",
    "            \n",
    "            predictions = []\n",
    "            \n",
    "            for idx, row in user_test.iterrows():\n",
    "                # Find all bigrams that start with prev_location\n",
    "                next_locations = {}\n",
    "                for (loc1, loc2), freq in bigram_counter.items():\n",
    "                    if loc1 == prev_location:\n",
    "                        next_locations[loc2] = freq\n",
    "                \n",
    "                if next_locations:\n",
    "                    # Sample from next locations\n",
    "                    locations = list(next_locations.keys())\n",
    "                    frequencies = list(next_locations.values())\n",
    "                    total_freq = sum(frequencies)\n",
    "                    probabilities = [f / total_freq for f in frequencies]\n",
    "                    \n",
    "                    if top_p is not None:\n",
    "                        # Apply top-p sampling\n",
    "                        selected_indices, selected_probs = top_p_sampling(probabilities, top_p)\n",
    "                        selected_locations = [locations[i] for i in selected_indices]\n",
    "                        sampled_location = np.random.choice(len(selected_locations), p=selected_probs)\n",
    "                        next_location = selected_locations[sampled_location]\n",
    "                    else:\n",
    "                        # Regular sampling\n",
    "                        sampled_idx = np.random.choice(len(locations), p=probabilities)\n",
    "                        next_location = locations[sampled_idx]\n",
    "                    \n",
    "                    predictions.append(next_location)\n",
    "                    prev_location = next_location\n",
    "                else:\n",
    "                    # Fallback to unigram model\n",
    "                    if uid in per_user_unigram_dict:\n",
    "                        unigram_counter = per_user_unigram_dict[uid]\n",
    "                        locations = list(unigram_counter.keys())\n",
    "                        frequencies = list(unigram_counter.values())\n",
    "                        total_freq = sum(frequencies)\n",
    "                        probabilities = [f / total_freq for f in frequencies]\n",
    "                        sampled_idx = np.random.choice(len(locations), p=probabilities)\n",
    "                        next_location = locations[sampled_idx]\n",
    "                    else:\n",
    "                        next_location = (gm_x, gm_y)\n",
    "                    \n",
    "                    predictions.append(next_location)\n",
    "                    prev_location = next_location\n",
    "            \n",
    "            # Update predictions for this user\n",
    "            user_indices = user_test.index\n",
    "            pred_bigram.loc[user_indices, \"x_pred\"] = [pred[0] for pred in predictions]\n",
    "            pred_bigram.loc[user_indices, \"y_pred\"] = [pred[1] for pred in predictions]\n",
    "            \n",
    "        else:\n",
    "            # Fallback to unigram model for users without bigram data\n",
    "            if uid in per_user_unigram_dict:\n",
    "                location_counter = per_user_unigram_dict[uid]\n",
    "                locations = list(location_counter.keys())\n",
    "                frequencies = list(location_counter.values())\n",
    "                total_freq = sum(frequencies)\n",
    "                probabilities = [f / total_freq for f in frequencies]\n",
    "                \n",
    "                num_samples = len(user_test)\n",
    "                sampled_indices = np.random.choice(len(locations), size=num_samples, p=probabilities)\n",
    "                sampled_locations = [locations[i] for i in sampled_indices]\n",
    "                \n",
    "                user_indices = user_test.index\n",
    "                pred_bigram.loc[user_indices, \"x_pred\"] = [loc[0] for loc in sampled_locations]\n",
    "                pred_bigram.loc[user_indices, \"y_pred\"] = [loc[1] for loc in sampled_locations]\n",
    "            else:\n",
    "                # Final fallback to global mean\n",
    "                mask = pred_bigram[\"uid\"] == uid\n",
    "                pred_bigram.loc[mask, \"x_pred\"] = gm_x\n",
    "                pred_bigram.loc[mask, \"y_pred\"] = gm_y\n",
    "    \n",
    "    return pred_bigram.astype({\"x_pred\": \"int16\", \"y_pred\": \"int16\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32639f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T12:32:44.121890Z",
     "iopub.status.busy": "2025-06-12T12:32:44.121584Z",
     "iopub.status.idle": "2025-06-12T12:32:44.136138Z",
     "shell.execute_reply": "2025-06-12T12:32:44.135213Z",
     "shell.execute_reply.started": "2025-06-12T12:32:44.121864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_city(city_code: str) -> dict:\n",
    "    \"\"\"\n",
    "    1. Compute train aggregates (with checkpointing)\n",
    "    2. Build test_df\n",
    "    3. Prepare gt_df\n",
    "    4. Build each baseline's pred_df (showing progress)\n",
    "    5. Evaluate GEO-BLEU (with tqdm inside evaluate_geobleu_parallel)\n",
    "    Returns dict: {baseline_name: GEO-BLEU score}.\n",
    "    \"\"\"\n",
    "    print(f\"\\n>>> Starting City {city_code}\")\n",
    "\n",
    "    # Check if results already exist\n",
    "    existing_results = load_checkpoint(f\"city_{city_code}_results\", \"results\")\n",
    "    if existing_results is not None:\n",
    "        print(f\"Found existing results for City {city_code}, skipping...\")\n",
    "        return existing_results\n",
    "\n",
    "    # 1) Train aggregates - check checkpoint first\n",
    "    aggregates = load_train_aggregates(city_code)\n",
    "    if aggregates is not None:\n",
    "        print(f\"Loaded cached train aggregates for City {city_code}\")\n",
    "        (gm_x, gm_y), (gmod_x, gmod_y), per_user_mean_df, per_user_mode_df, per_user_unigram_dict, per_user_bigram_dict = aggregates\n",
    "    else:\n",
    "        print(f\"Computing train aggregates for City {city_code}\")\n",
    "        aggregates = compute_train_aggregates(city_code)\n",
    "        (gm_x, gm_y), (gmod_x, gmod_y), per_user_mean_df, per_user_mode_df, per_user_unigram_dict, per_user_bigram_dict = aggregates\n",
    "        # Save aggregates checkpoint\n",
    "        save_train_aggregates(city_code, aggregates)\n",
    "\n",
    "    # 2) Test DataFrame\n",
    "    test_df = build_test_dataframe(city_code)\n",
    "\n",
    "    # 3) Ground-truth DataFrame\n",
    "    gt_df = test_df.rename(columns={\"x\": \"x_gt\", \"y\": \"y_gt\"})[[\"uid\", \"d\", \"t\", \"x_gt\", \"y_gt\"]]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # 4a) Global Mean Prediction\n",
    "    print(f\"City {city_code} -> Global Mean prediction ...\")\n",
    "    pred_gm = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_gm[\"x_pred\"] = gm_x\n",
    "    pred_gm[\"y_pred\"] = gm_y\n",
    "    score_gm = evaluate_geobleu_parallel(pred_gm, gt_df)\n",
    "    results[\"Global Mean\"] = round(score_gm, 5)\n",
    "    print(f\"Global Mean GEO-BLEU = {results['Global Mean']}\")\n",
    "\n",
    "    # 4b) Global Mode Prediction\n",
    "    print(f\"City {city_code} -> Global Mode prediction ...\")\n",
    "    pred_gmod = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_gmod[\"x_pred\"] = gmod_x\n",
    "    pred_gmod[\"y_pred\"] = gmod_y\n",
    "    score_gmod = evaluate_geobleu_parallel(pred_gmod, gt_df)\n",
    "    results[\"Global Mode\"] = round(score_gmod, 5)\n",
    "    print(f\"Global Mode GEO-BLEU = {results['Global Mode']}\")\n",
    "\n",
    "    # 4c) Per-User Mean Prediction\n",
    "    print(f\"City {city_code} -> Per-User Mean prediction ...\")\n",
    "    pred_pum = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_pum = pred_pum.join(per_user_mean_df, on=\"uid\", how=\"left\", rsuffix=\"_tmp\")\n",
    "    pred_pum = pred_pum.rename(columns={\"x\": \"x_pred\", \"y\": \"y_pred\"})\n",
    "    # Fallback for unseen users\n",
    "    pred_pum[\"x_pred\"] = pred_pum[\"x_pred\"].fillna(gm_x).astype(\"int16\")\n",
    "    pred_pum[\"y_pred\"] = pred_pum[\"y_pred\"].fillna(gm_y).astype(\"int16\")\n",
    "    score_pum = evaluate_geobleu_parallel(pred_pum, gt_df)\n",
    "    results[\"Per-User Mean\"] = round(score_pum, 5)\n",
    "    print(f\"Per-User Mean GEO-BLEU = {results['Per-User Mean']}\")\n",
    "\n",
    "    # 4d) Per-User Mode Prediction\n",
    "    print(f\"City {city_code} -> Per-User Mode prediction ...\")\n",
    "    pred_pumod = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_pumod = pred_pumod.join(per_user_mode_df, on=\"uid\", how=\"left\", rsuffix=\"_tmp\")\n",
    "    pred_pumod = pred_pumod.rename(columns={\"x\": \"x_pred\", \"y\": \"y_pred\"})\n",
    "    # Fallback for unseen users\n",
    "    pred_pumod[\"x_pred\"] = pred_pumod[\"x_pred\"].fillna(gmod_x).astype(\"int16\")\n",
    "    pred_pumod[\"y_pred\"] = pred_pumod[\"y_pred\"].fillna(gmod_y).astype(\"int16\")\n",
    "    score_pumod = evaluate_geobleu_parallel(pred_pumod, gt_df)\n",
    "    results[\"Per-User Mode\"] = round(score_pumod, 5)\n",
    "    print(f\"Per-User Mode GEO-BLEU = {results['Per-User Mode']}\")\n",
    "\n",
    "    # 4e) Unigram Model Prediction\n",
    "    print(f\"City {city_code} -> Unigram Model prediction ...\")\n",
    "    pred_unigram = generate_unigram_predictions(test_df, per_user_unigram_dict, gm_x, gm_y)\n",
    "    score_unigram = evaluate_geobleu_parallel(pred_unigram, gt_df)\n",
    "    results[\"Unigram Model\"] = round(score_unigram, 5)\n",
    "    print(f\"Unigram Model GEO-BLEU = {results['Unigram Model']}\")\n",
    "\n",
    "    # 4f) Bigram Model Prediction\n",
    "    print(f\"City {city_code} -> Bigram Model prediction ...\")\n",
    "    pred_bigram = generate_bigram_predictions(test_df, per_user_bigram_dict, per_user_unigram_dict, gm_x, gm_y)\n",
    "    score_bigram = evaluate_geobleu_parallel(pred_bigram, gt_df)\n",
    "    results[\"Bigram Model\"] = round(score_bigram, 5)\n",
    "    print(f\"Bigram Model GEO-BLEU = {results['Bigram Model']}\")\n",
    "\n",
    "    # 4g) Bigram Model with top_p=0.7 Prediction\n",
    "    print(f\"City {city_code} -> Bigram Model (top_p=0.7) prediction ...\")\n",
    "    pred_bigram_top_p = generate_bigram_predictions(test_df, per_user_bigram_dict, per_user_unigram_dict, gm_x, gm_y, top_p=0.7)\n",
    "    score_bigram_top_p = evaluate_geobleu_parallel(pred_bigram_top_p, gt_df)\n",
    "    results[\"Bigram Model (top_p=0.7)\"] = round(score_bigram_top_p, 5)\n",
    "    print(f\"Bigram Model (top_p=0.7) GEO-BLEU = {results['Bigram Model (top_p=0.7)']}\")\n",
    "\n",
    "    # Save city results checkpoint\n",
    "    save_checkpoint(results, f\"city_{city_code}_results\", \"results\")\n",
    "\n",
    "    print(f\"<<< Finished City {city_code} with results: {results}\\n\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dccd9-5e58-4bdc-8f19-47d491c763b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T10:05:21.446839Z",
     "iopub.status.busy": "2025-06-12T10:05:21.446526Z",
     "iopub.status.idle": "2025-06-12T10:06:42.545633Z",
     "shell.execute_reply": "2025-06-12T10:06:42.544528Z",
     "shell.execute_reply.started": "2025-06-12T10:05:21.446818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA COVERAGE ANALYSIS\n",
      "============================================================\n",
      ">>> Analyzing data coverage for City A ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc626d3d37247ceaf9a32f8ebab286a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing coverage (City A): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Coverage Summary for City A ===\n",
      "Overall Statistics:\n",
      "   Total unique users: 150,000\n",
      "   Users in training: 150,000\n",
      "   Users in testing: 150,000\n",
      "\n",
      "Training Period (Days 1-60):\n",
      "   Total entries: 67,862,502\n",
      "   Unmasked entries: 67,862,502 (100.00%)\n",
      "   Masked entries: 0 (0.00%)\n",
      "\n",
      "Test Period (Days 61+):\n",
      "   Total entries: 19,179,916\n",
      "   Unmasked entries: 18,859,525 (98.33%)\n",
      "   Masked entries: 320,391 (1.67%)\n",
      "\n",
      "Evaluation will be performed on 18,859,525 test entries\n",
      "\n",
      ">>> Analyzing data coverage for City B ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639a3016b11a4511b51b584dc70f8b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing coverage (City B): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Coverage Summary for City B ===\n",
      "Overall Statistics:\n",
      "   Total unique users: 30,000\n",
      "   Users in training: 30,000\n",
      "   Users in testing: 30,000\n",
      "\n",
      "Training Period (Days 1-60):\n",
      "   Total entries: 14,194,433\n",
      "   Unmasked entries: 14,194,433 (100.00%)\n",
      "   Masked entries: 0 (0.00%)\n",
      "\n",
      "Test Period (Days 61+):\n",
      "   Total entries: 4,002,560\n",
      "   Unmasked entries: 3,627,062 (90.62%)\n",
      "   Masked entries: 375,498 (9.38%)\n",
      "\n",
      "Evaluation will be performed on 3,627,062 test entries\n",
      "\n",
      ">>> Analyzing data coverage for City C ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd0bd44b71b4af89a90baeffd25ce46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing coverage (City C): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Coverage Summary for City C ===\n",
      "Overall Statistics:\n",
      "   Total unique users: 25,000\n",
      "   Users in training: 25,000\n",
      "   Users in testing: 25,000\n",
      "\n",
      "Training Period (Days 1-60):\n",
      "   Total entries: 11,226,812\n",
      "   Unmasked entries: 11,226,812 (100.00%)\n",
      "   Masked entries: 0 (0.00%)\n",
      "\n",
      "Test Period (Days 61+):\n",
      "   Total entries: 3,248,335\n",
      "   Unmasked entries: 2,953,708 (90.93%)\n",
      "   Masked entries: 294,627 (9.07%)\n",
      "\n",
      "Evaluation will be performed on 2,953,708 test entries\n",
      "\n",
      ">>> Analyzing data coverage for City D ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f186d676ba0049e18c029b9c35b30464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing coverage (City D): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Coverage Summary for City D ===\n",
      "Overall Statistics:\n",
      "   Total unique users: 20,000\n",
      "   Users in training: 20,000\n",
      "   Users in testing: 20,000\n",
      "\n",
      "Training Period (Days 1-60):\n",
      "   Total entries: 9,358,783\n",
      "   Unmasked entries: 9,358,783 (100.00%)\n",
      "   Masked entries: 0 (0.00%)\n",
      "\n",
      "Test Period (Days 61+):\n",
      "   Total entries: 2,671,295\n",
      "   Unmasked entries: 2,361,882 (88.42%)\n",
      "   Masked entries: 309,413 (11.58%)\n",
      "\n",
      "Evaluation will be performed on 2,361,882 test entries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def analyze_data_coverage(city_code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze masked vs unmasked entries in the dataset for a given city.\n",
    "    Returns statistics about data coverage across training and test periods.\n",
    "    \"\"\"\n",
    "    # Check if coverage analysis already exists\n",
    "    existing_coverage = load_checkpoint(f\"city_{city_code}_coverage\", \"coverage\")\n",
    "    if existing_coverage is not None:\n",
    "        print(f\"Found existing coverage analysis for City {city_code}\")\n",
    "        return existing_coverage\n",
    "    \n",
    "    print(f\">>> Analyzing data coverage for City {city_code} ...\")\n",
    "    \n",
    "    path = os.path.join(DATA_DIR, f\"city_{city_code}_challengedata.csv\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    stats = {\n",
    "        'train_total': 0,\n",
    "        'train_masked': 0,\n",
    "        'train_unmasked': 0,\n",
    "        'test_total': 0,\n",
    "        'test_masked': 0,\n",
    "        'test_unmasked': 0,\n",
    "        'unique_users': set(),\n",
    "        'train_users': set(),\n",
    "        'test_users': set()\n",
    "    }\n",
    "    \n",
    "    # Process data in chunks\n",
    "    for chunk in tqdm(pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE),\n",
    "                      desc=f\"Analyzing coverage (City {city_code})\"):\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_chunk = chunk[chunk[\"d\"] <= TRAIN_DAY_MAX]\n",
    "        test_chunk = chunk[chunk[\"d\"] >= TEST_DAY_MIN]\n",
    "        \n",
    "        # Update unique users\n",
    "        stats['unique_users'].update(chunk['uid'].unique())\n",
    "        \n",
    "        # Training data analysis\n",
    "        if not train_chunk.empty:\n",
    "            stats['train_total'] += len(train_chunk)\n",
    "            masked_train = (train_chunk[\"x\"] == MASK_VALUE) | (train_chunk[\"y\"] == MASK_VALUE)\n",
    "            stats['train_masked'] += masked_train.sum()\n",
    "            stats['train_unmasked'] += (~masked_train).sum()\n",
    "            stats['train_users'].update(train_chunk['uid'].unique())\n",
    "        \n",
    "        # Test data analysis\n",
    "        if not test_chunk.empty:\n",
    "            stats['test_total'] += len(test_chunk)\n",
    "            masked_test = (test_chunk[\"x\"] == MASK_VALUE) | (test_chunk[\"y\"] == MASK_VALUE)\n",
    "            stats['test_masked'] += masked_test.sum()\n",
    "            stats['test_unmasked'] += (~masked_test).sum()\n",
    "            stats['test_users'].update(test_chunk['uid'].unique())\n",
    "        \n",
    "        del chunk, train_chunk, test_chunk\n",
    "    \n",
    "    # Convert sets to counts for JSON serialization\n",
    "    coverage_stats = {\n",
    "        'train_total': stats['train_total'],\n",
    "        'train_masked': stats['train_masked'],\n",
    "        'train_unmasked': stats['train_unmasked'],\n",
    "        'test_total': stats['test_total'],\n",
    "        'test_masked': stats['test_masked'],\n",
    "        'test_unmasked': stats['test_unmasked'],\n",
    "        'unique_users': len(stats['unique_users']),\n",
    "        'train_users': len(stats['train_users']),\n",
    "        'test_users': len(stats['test_users'])\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages\n",
    "    if coverage_stats['train_total'] > 0:\n",
    "        coverage_stats['train_masked_pct'] = (coverage_stats['train_masked'] / coverage_stats['train_total']) * 100\n",
    "        coverage_stats['train_unmasked_pct'] = (coverage_stats['train_unmasked'] / coverage_stats['train_total']) * 100\n",
    "    else:\n",
    "        coverage_stats['train_masked_pct'] = coverage_stats['train_unmasked_pct'] = 0\n",
    "    \n",
    "    if coverage_stats['test_total'] > 0:\n",
    "        coverage_stats['test_masked_pct'] = (coverage_stats['test_masked'] / coverage_stats['test_total']) * 100\n",
    "        coverage_stats['test_unmasked_pct'] = (coverage_stats['test_unmasked'] / coverage_stats['test_total']) * 100\n",
    "    else:\n",
    "        coverage_stats['test_masked_pct'] = coverage_stats['test_unmasked_pct'] = 0\n",
    "    \n",
    "    # Save coverage checkpoint\n",
    "    save_checkpoint(coverage_stats, f\"city_{city_code}_coverage\", \"coverage\")\n",
    "    \n",
    "    return coverage_stats\n",
    "\n",
    "def print_coverage_summary(stats: dict, city_code: str):\n",
    "    \"\"\"Print a formatted summary of data coverage statistics.\"\"\"\n",
    "    print(f\"\\n=== Data Coverage Summary for City {city_code} ===\")\n",
    "    print(f\"Overall Statistics:\")\n",
    "    print(f\"   Total unique users: {stats['unique_users']:,}\")\n",
    "    print(f\"   Users in training: {stats['train_users']:,}\")\n",
    "    print(f\"   Users in testing: {stats['test_users']:,}\")\n",
    "    \n",
    "    print(f\"\\nTraining Period (Days 1-{TRAIN_DAY_MAX}):\")\n",
    "    print(f\"   Total entries: {stats['train_total']:,}\")\n",
    "    print(f\"   Unmasked entries: {stats['train_unmasked']:,} ({stats['train_unmasked_pct']:.2f}%)\")\n",
    "    print(f\"   Masked entries: {stats['train_masked']:,} ({stats['train_masked_pct']:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nTest Period (Days {TEST_DAY_MIN}+):\")\n",
    "    print(f\"   Total entries: {stats['test_total']:,}\")\n",
    "    print(f\"   Unmasked entries: {stats['test_unmasked']:,} ({stats['test_unmasked_pct']:.2f}%)\")\n",
    "    print(f\"   Masked entries: {stats['test_masked']:,} ({stats['test_masked_pct']:.2f}%)\")\n",
    "    \n",
    "    if stats['test_unmasked'] > 0:\n",
    "        print(f\"\\nEvaluation will be performed on {stats['test_unmasked']:,} test entries\")\n",
    "    else:\n",
    "        print(f\"\\nNo unmasked test entries found!\")\n",
    "\n",
    "# Run coverage analysis for all cities\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA COVERAGE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List existing checkpoints\n",
    "list_checkpoints()\n",
    "print()\n",
    "\n",
    "all_coverage_stats = {}\n",
    "for city in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "    coverage_stats = analyze_data_coverage(city)\n",
    "    all_coverage_stats[city] = coverage_stats\n",
    "    print_coverage_summary(coverage_stats, city)\n",
    "    print()\n",
    "\n",
    "# Save all coverage stats\n",
    "save_checkpoint(all_coverage_stats, \"all_cities_coverage\", \"coverage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f60ca3-2bac-44a9-8333-2504917c34d8",
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-12T09:59:43.269Z",
     "iopub.execute_input": "2025-06-12T06:26:44.153424Z",
     "iopub.status.busy": "2025-06-12T06:26:44.153100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting City B\n",
      ">>> Computing train aggregates for City B ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabd0653d727457c850ed2008a4f8723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading chunks (City B): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train aggregates done: GM=(104,64), GMODE=(90,49), 30000 users' means, 30000 users' modes, 30000 users' unigrams, 30000 users' bigrams.\n",
      ">>> Building test DataFrame for City B ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb65607c9c34e85a957df47353b81d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading test chunks (City B): 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame built: shape = (3627062, 5)\n",
      "City B -> Global Mean prediction ...\n",
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e05977079644cc85e1c3901dedc31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mean GEO-BLEU = 0.00025\n",
      "City B -> Global Mode prediction ...\n",
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802555aa2e07406bb518157a7f235c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Mode GEO-BLEU = 0.00419\n",
      "City B -> Per-User Mean prediction ...\n",
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96b2557e2e845fc8d3840e9643e8120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-User Mean GEO-BLEU = 0.01778\n",
      "City B -> Per-User Mode prediction ...\n",
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dd9e7b3dc242c4ae17e023f128f070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-User Mode GEO-BLEU = 0.0842\n",
      "City B -> Unigram Model prediction ...\n",
      "Generating Unigram predictions ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b0a19c36c146feb6c2697397470134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unigram sampling:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbe6f7a8a2c4e29805dd69222f240b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Model GEO-BLEU = 0.04105\n",
      "City B -> Bigram Model prediction ...\n",
      "Generating Bigram Model predictions ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576dca6a9dd145568742351caf17101b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bigram Model sampling:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ▶ Evaluating GEO-BLEU on 27000 users...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36f95ad89c34cd797aa637ec16ff28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "      GEO-BLEU:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram Model GEO-BLEU = 0.05974\n",
      "City B -> Bigram Model (top_p=0.7) prediction ...\n",
      "Generating Bigram Model (top_p=0.7) predictions ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c4617be294cf4b9ab67418920a219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bigram Model (top_p=0.7) sampling:   0%|          | 0/27000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods = [\"Global Mean\", \"Global Mode\", \"Per-User Mean\", \"Per-User Mode\", \"Unigram Model\", \"Bigram Model\", \"Bigram Model (top_p=0.7)\"]\n",
    "\n",
    "# Check if final results already exist\n",
    "existing_final_results = load_checkpoint(\"final_results_df\", \"results\")\n",
    "if existing_final_results is not None:\n",
    "    print(\"Found existing final results, loading from checkpoint...\")\n",
    "    df_results = existing_final_results\n",
    "else:\n",
    "    print(\"Computing results for all cities...\")\n",
    "    all_scores = {method: [] for method in methods}\n",
    "\n",
    "    for city in CITIES:\n",
    "        city_scores = process_city(city)\n",
    "        for method in methods:\n",
    "            all_scores[method].append(city_scores[method])\n",
    "\n",
    "    df_results = pd.DataFrame(\n",
    "        all_scores,\n",
    "        index=[f\"City {c}\" for c in CITIES]\n",
    "    ).T\n",
    "    df_results[\"Average\"] = df_results.mean(axis=1)\n",
    "    \n",
    "    # Save final results checkpoint\n",
    "    save_checkpoint(df_results, \"final_results_df\", \"results\")\n",
    "    \n",
    "    # Also save as JSON for easy reading\n",
    "    results_dict = df_results.to_dict()\n",
    "    save_checkpoint(results_dict, \"final_results_dict\", \"results\")\n",
    "\n",
    "print(\"\\n=== Final GEO-BLEU Scores ===\")\n",
    "display(df_results)\n",
    "\n",
    "# Save a summary report\n",
    "summary_report = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'cities_evaluated': CITIES,\n",
    "    'methods_evaluated': methods,\n",
    "    'best_method': df_results['Average'].idxmax(),\n",
    "    'best_score': float(df_results['Average'].max()),\n",
    "    'results_summary': df_results.to_dict()\n",
    "}\n",
    "\n",
    "save_checkpoint(summary_report, \"evaluation_summary\", \"results\")\n",
    "\n",
    "print(f\"\\nBest performing method: {summary_report['best_method']} (Score: {summary_report['best_score']:.5f})\")\n",
    "print(f\"All results saved to: {CHECKPOINT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility cell for checkpoint management\n",
    "def clean_checkpoints(keep_final=True):\n",
    "    \"\"\"Clean up checkpoint files, optionally keeping final results.\"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    if os.path.exists(CHECKPOINT_DIR):\n",
    "        if keep_final and os.path.exists(os.path.join(CHECKPOINT_DIR, \"results_final_results_df.pkl\")):\n",
    "            # Keep only final results\n",
    "            final_files = []\n",
    "            for file in os.listdir(CHECKPOINT_DIR):\n",
    "                if \"final_results\" in file or \"evaluation_summary\" in file:\n",
    "                    final_files.append(file)\n",
    "            \n",
    "            # Create temp directory and move final files\n",
    "            temp_dir = f\"{CHECKPOINT_DIR}_temp\"\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            for file in final_files:\n",
    "                shutil.move(os.path.join(CHECKPOINT_DIR, file), os.path.join(temp_dir, file))\n",
    "            \n",
    "            # Remove original directory and rename temp\n",
    "            shutil.rmtree(CHECKPOINT_DIR)\n",
    "            shutil.move(temp_dir, CHECKPOINT_DIR)\n",
    "            \n",
    "            print(f\"Cleaned checkpoints, kept final results in {CHECKPOINT_DIR}\")\n",
    "        else:\n",
    "            shutil.rmtree(CHECKPOINT_DIR)\n",
    "            print(f\"Removed all checkpoints from {CHECKPOINT_DIR}\")\n",
    "    else:\n",
    "        print(\"No checkpoint directory found.\")\n",
    "\n",
    "def get_checkpoint_summary():\n",
    "    \"\"\"Get a summary of all checkpoints.\"\"\"\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        print(\"No checkpoint directory found.\")\n",
    "        return\n",
    "    \n",
    "    files = os.listdir(CHECKPOINT_DIR)\n",
    "    checkpoints_by_type = defaultdict(list)\n",
    "    \n",
    "    for file in files:\n",
    "        if not file.endswith('_meta.json'):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(CHECKPOINT_DIR, file), 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "            checkpoints_by_type[metadata['type']].append({\n",
    "                'name': file.replace('_meta.json', ''),\n",
    "                'timestamp': metadata['timestamp'],\n",
    "                'data_type': metadata.get('data_type', 'unknown')\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(\"Checkpoint Summary:\")\n",
    "    for checkpoint_type, checkpoints in checkpoints_by_type.items():\n",
    "        print(f\"\\n{checkpoint_type.upper()} ({len(checkpoints)} files):\")\n",
    "        for cp in sorted(checkpoints, key=lambda x: x['timestamp']):\n",
    "            print(f\"  • {cp['name']} ({cp['data_type']}) - {cp['timestamp']}\")\n",
    "\n",
    "# Uncomment to run checkpoint utilities\n",
    "# get_checkpoint_summary()\n",
    "# clean_checkpoints(keep_final=True)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7587200,
     "sourceId": 12055345,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
