{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560f98c2",
   "metadata": {
    "papermill": {
     "duration": 0.003311,
     "end_time": "2025-07-29T15:59:17.670869",
     "exception": false,
     "start_time": "2025-07-29T15:59:17.667558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ALGORITHM: Flat TT-KNN for Location Prediction\n",
    "\n",
    "INPUT: Historical trajectories, test sequences with masked locations\n",
    "OUTPUT: Predicted locations for masked entries\n",
    "\n",
    "PHASE 1: Training\n",
    "FOR each user:\n",
    "    1. Filter locations by frequency (≥ τ visits)\n",
    "    2. Convert (day, time) → flat time segments\n",
    "    3. Build transition table: segment → location → [next_locations]\n",
    "    4. Store only transitions within M future segments\n",
    "\n",
    "PHASE 2: Prediction\n",
    "FOR each masked location:\n",
    "    1. Get current location and time segment\n",
    "    2. Look up possible next locations in future segments (1 to M)\n",
    "    3. Find K nearest neighbors by Euclidean distance\n",
    "    4. Return closest different location, or current if none found\n",
    "\n",
    "PHASE 3: Evaluation\n",
    "1. Sample fraction of unmasked test data\n",
    "2. Mask their locations and predict\n",
    "3. Calculate GEO-BLEU score against ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8944f1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:17.679191Z",
     "iopub.status.busy": "2025-07-29T15:59:17.678292Z",
     "iopub.status.idle": "2025-07-29T15:59:30.336716Z",
     "shell.execute_reply": "2025-07-29T15:59:30.335667Z"
    },
    "papermill": {
     "duration": 12.664534,
     "end_time": "2025-07-29T15:59:30.338613",
     "exception": false,
     "start_time": "2025-07-29T15:59:17.674079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for geobleu (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary package\n",
    "%pip install -q git+https://github.com/yahoojapan/geobleu.git tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "from geobleu import calc_geobleu_single\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec73533e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.345982Z",
     "iopub.status.busy": "2025-07-29T15:59:30.345439Z",
     "iopub.status.idle": "2025-07-29T15:59:30.351528Z",
     "shell.execute_reply": "2025-07-29T15:59:30.350540Z"
    },
    "papermill": {
     "duration": 0.011325,
     "end_time": "2025-07-29T15:59:30.352975",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.341650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flat TT-KNN configuration\n",
    "# TTKNN_VALUES = {\n",
    "#     \"TAU\": 5,\n",
    "#     \"DELTA\": 30,   # 30 minutes\n",
    "#     \"M\": 2,        # future segments\n",
    "#     \"K\": 2,        # nearest neighbors\n",
    "#     \"SAMPLE_FRAC\": 0.1  # fraction of unmasked test data to simulate prediction\n",
    "# }\n",
    "\n",
    "# Dataset setup\n",
    "DATA_DIR = \"/kaggle/input/humob-data/15313913\"\n",
    "CITIES = [\"A\"]  # Change to [\"A\", \"B\", \"C\", \"D\"] for all\n",
    "COLUMNS = [\"uid\", \"d\", \"t\", \"x\", \"y\"]\n",
    "DTYPES = {\"uid\": \"int32\", \"d\": \"int8\", \"t\": \"int8\", \"x\": \"int16\", \"y\": \"int16\"}\n",
    "TRAIN_DAY_MAX = 60\n",
    "TEST_DAY_MIN = 61\n",
    "TEST_DAY_MAX = 75  # Added upper bound for test period\n",
    "MASK_VALUE = 999\n",
    "CHUNK_SIZE = 500_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1221e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.360093Z",
     "iopub.status.busy": "2025-07-29T15:59:30.359781Z",
     "iopub.status.idle": "2025-07-29T15:59:30.367179Z",
     "shell.execute_reply": "2025-07-29T15:59:30.366471Z"
    },
    "papermill": {
     "duration": 0.012614,
     "end_time": "2025-07-29T15:59:30.368662",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.356048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(loc1, loc2):\n",
    "    return np.sqrt((loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2)\n",
    "\n",
    "def manhattan_distance(loc1, loc2):\n",
    "    return abs(loc1[0] - loc2[0]) + abs(loc1[1] - loc2[1])\n",
    "\n",
    "def chebyshev_distance(loc1, loc2):\n",
    "    return max(abs(loc1[0] - loc2[0]), abs(loc1[1] - loc2[1]))\n",
    "\n",
    "def calculate_distance(loc1, loc2, distance_type='euclidean'):\n",
    "    if distance_type == 'euclidean':\n",
    "        return euclidean_distance(loc1, loc2)\n",
    "    elif distance_type == 'manhattan':\n",
    "        return manhattan_distance(loc1, loc2)\n",
    "    elif distance_type == 'chebyshev':\n",
    "        return chebyshev_distance(loc1, loc2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown distance type: {distance_type}\")\n",
    "\n",
    "def to_flat_segment(d, t, delta=30):\n",
    "    segments_per_day = (24 * 60) // delta\n",
    "    return d * segments_per_day + (t * 60) // delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b14ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.376125Z",
     "iopub.status.busy": "2025-07-29T15:59:30.375771Z",
     "iopub.status.idle": "2025-07-29T15:59:30.383259Z",
     "shell.execute_reply": "2025-07-29T15:59:30.382196Z"
    },
    "papermill": {
     "duration": 0.013245,
     "end_time": "2025-07-29T15:59:30.385042",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.371797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_flat_TT_index(trajectory, tau=5, delta=30):\n",
    "    location_counts = Counter((x, y) for _, _, x, y in trajectory)\n",
    "    traj_filtered = [(d, t, x, y) for (d, t, x, y) in trajectory if location_counts[(x, y)] >= tau]\n",
    "    \n",
    "    seg_traj = [(to_flat_segment(d, t, delta), (x, y)) for d, t, x, y in traj_filtered]\n",
    "    seg_traj.sort()\n",
    "    \n",
    "    TT_index = defaultdict(lambda: defaultdict(list))\n",
    "    # Also track frequency of transitions\n",
    "    TT_freq = defaultdict(lambda: defaultdict(Counter))\n",
    "    \n",
    "    for i in range(len(seg_traj) - 1):\n",
    "        seg1, loc1 = seg_traj[i]\n",
    "        seg2, loc2 = seg_traj[i + 1]\n",
    "        if 0 < seg2 - seg1 <= 3:  # allow up to 3-segment jumps (1.5 hours for Δ=30min)\n",
    "            TT_index[seg1][loc1].append(loc2)\n",
    "            TT_freq[seg1][loc1][loc2] += 1\n",
    "\n",
    "    return TT_index, TT_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3abbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.392844Z",
     "iopub.status.busy": "2025-07-29T15:59:30.392499Z",
     "iopub.status.idle": "2025-07-29T15:59:30.404681Z",
     "shell.execute_reply": "2025-07-29T15:59:30.403357Z"
    },
    "papermill": {
     "duration": 0.018111,
     "end_time": "2025-07-29T15:59:30.406499",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.388388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Improved prediction function with better frequency weighting\n",
    "def predict_next_location_flat(TT_index, TT_freq, d, t, current_loc, M=2, K=2, delta=30, distance_type='euclidean', freq_weight=0.3):\n",
    "    curr_seg = to_flat_segment(d, t, delta)\n",
    "    candidates = []\n",
    "    candidate_freqs = []\n",
    "\n",
    "    # Look ahead in future segments\n",
    "    for i in range(1, M + 1):\n",
    "        future_seg = curr_seg + i\n",
    "        if future_seg in TT_index and current_loc in TT_index[future_seg]:\n",
    "            locs = TT_index[future_seg][current_loc]\n",
    "            freqs = [TT_freq[future_seg][current_loc][loc] for loc in locs]\n",
    "            candidates.extend(locs)\n",
    "            candidate_freqs.extend(freqs)\n",
    "\n",
    "    if not candidates:\n",
    "        return current_loc\n",
    "\n",
    "    # Create unique candidates with aggregated frequencies\n",
    "    unique_candidates = {}\n",
    "    for loc, freq in zip(candidates, candidate_freqs):\n",
    "        if loc in unique_candidates:\n",
    "            unique_candidates[loc] += freq\n",
    "        else:\n",
    "            unique_candidates[loc] = freq\n",
    "\n",
    "    # Calculate weighted scores\n",
    "    scored_candidates = []\n",
    "    max_freq = max(unique_candidates.values()) if unique_candidates else 1\n",
    "    min_distance = float('inf')\n",
    "    max_distance = 0\n",
    "    \n",
    "    # First pass: calculate distance range for normalization\n",
    "    distances = {}\n",
    "    for loc in unique_candidates:\n",
    "        dist = calculate_distance(current_loc, loc, distance_type)\n",
    "        distances[loc] = dist\n",
    "        min_distance = min(min_distance, dist)\n",
    "        max_distance = max(max_distance, dist)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    distance_range = max_distance - min_distance if max_distance > min_distance else 1\n",
    "    \n",
    "    for loc, freq in unique_candidates.items():\n",
    "        distance = distances[loc]\n",
    "        \n",
    "        # Normalize both distance and frequency to [0, 1]\n",
    "        norm_distance = (distance - min_distance) / distance_range if distance_range > 0 else 0\n",
    "        norm_freq = freq / max_freq\n",
    "        \n",
    "        # Combined score: balance between distance (lower is better) and frequency (higher is better)\n",
    "        # Use exponential weighting for frequency to give more preference to frequent locations\n",
    "        freq_bonus = norm_freq ** freq_weight\n",
    "        weighted_score = norm_distance / freq_bonus  # Lower score is better\n",
    "        \n",
    "        scored_candidates.append((weighted_score, loc))\n",
    "\n",
    "    # Sort by weighted score and return best different location\n",
    "    scored_candidates.sort()\n",
    "    \n",
    "    for _, loc in scored_candidates[:K]:\n",
    "        if loc != current_loc:\n",
    "            return loc\n",
    "    return current_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f011ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.414808Z",
     "iopub.status.busy": "2025-07-29T15:59:30.414469Z",
     "iopub.status.idle": "2025-07-29T15:59:30.423088Z",
     "shell.execute_reply": "2025-07-29T15:59:30.422067Z"
    },
    "papermill": {
     "duration": 0.014964,
     "end_time": "2025-07-29T15:59:30.424827",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.409863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FlatTTKNNModel:\n",
    "    def __init__(self, tau=5, delta=30, M=2, K=2, distance_type='euclidean', freq_weight=0.3):\n",
    "        self.tau = tau\n",
    "        self.delta = delta\n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.distance_type = distance_type\n",
    "        self.freq_weight = freq_weight\n",
    "        self.index = {}\n",
    "        self.freq_index = {}\n",
    "\n",
    "    def fit(self, user_trajectories):\n",
    "        for uid, traj in tqdm(user_trajectories.items(), desc=\"Building TT indices\"):\n",
    "            formatted = [(d, t, x, y) for (x, y), (d, t) in traj]\n",
    "            self.index[uid], self.freq_index[uid] = build_flat_TT_index(formatted, self.tau, self.delta)\n",
    "\n",
    "    def predict(self, uid, d, t, current_loc):\n",
    "        if uid not in self.index:\n",
    "            return current_loc\n",
    "        return predict_next_location_flat(\n",
    "            self.index[uid], \n",
    "            self.freq_index[uid], \n",
    "            d, t, current_loc, \n",
    "            self.M, self.K, self.delta, \n",
    "            self.distance_type, \n",
    "            self.freq_weight\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5129147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.432653Z",
     "iopub.status.busy": "2025-07-29T15:59:30.432247Z",
     "iopub.status.idle": "2025-07-29T15:59:30.449232Z",
     "shell.execute_reply": "2025-07-29T15:59:30.448461Z"
    },
    "papermill": {
     "duration": 0.022662,
     "end_time": "2025-07-29T15:59:30.450723",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.428061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_training_data(city, validation_indices=None):\n",
    "    \"\"\"Load training data from days 1-60 and unmasked data from days 61-75 (excluding validation samples)\"\"\"\n",
    "    path = f\"{DATA_DIR}/city_{city}_challengedata.csv\"\n",
    "    user_trajs = defaultdict(list)\n",
    "    \n",
    "    # Track validation indices to exclude from training\n",
    "    validation_set = set()\n",
    "    if validation_indices is not None:\n",
    "        validation_set = set(validation_indices)\n",
    "    \n",
    "    chunk_counter = 0\n",
    "    for chunk in pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE):\n",
    "        # Training data from days 1-60\n",
    "        train_early = chunk[chunk[\"d\"] <= TRAIN_DAY_MAX]\n",
    "        \n",
    "        # Additional training data from days 61-75 (unmasked, not in validation)\n",
    "        test_period = chunk[(chunk[\"d\"] >= TEST_DAY_MIN) & (chunk[\"d\"] <= TEST_DAY_MAX) & (chunk[\"x\"] != MASK_VALUE)]\n",
    "        \n",
    "        # Filter out validation samples from test period data\n",
    "        if not test_period.empty and validation_indices is not None:\n",
    "            # Calculate global indices for this chunk\n",
    "            chunk_start_idx = chunk_counter * CHUNK_SIZE\n",
    "            chunk_indices = set(range(chunk_start_idx, chunk_start_idx + len(chunk)))\n",
    "            test_period_global_indices = set(test_period.index + chunk_start_idx)\n",
    "            \n",
    "            # Keep only test period data that's not in validation\n",
    "            valid_test_indices = test_period_global_indices - validation_set\n",
    "            if valid_test_indices:\n",
    "                # Convert back to local chunk indices\n",
    "                local_valid_indices = [idx - chunk_start_idx for idx in valid_test_indices if idx - chunk_start_idx < len(chunk)]\n",
    "                if local_valid_indices:\n",
    "                    train_additional = chunk.iloc[local_valid_indices]\n",
    "                else:\n",
    "                    train_additional = pd.DataFrame()\n",
    "            else:\n",
    "                train_additional = pd.DataFrame()\n",
    "        else:\n",
    "            train_additional = test_period\n",
    "        \n",
    "        # Combine training data\n",
    "        combined_train = pd.concat([train_early, train_additional], ignore_index=True)\n",
    "        \n",
    "        # Process trajectories\n",
    "        for uid, group in combined_train.groupby(\"uid\"):\n",
    "            locs = list(zip(group[\"x\"], group[\"y\"]))\n",
    "            times = list(zip(group[\"d\"], group[\"t\"]))\n",
    "            user_trajs[uid].extend(zip(locs, times))\n",
    "        \n",
    "        chunk_counter += 1\n",
    "    \n",
    "    print(f\"Training data loaded: {sum(len(traj) for traj in user_trajs.values())} total points\")\n",
    "    return dict(user_trajs)\n",
    "\n",
    "def load_validation_data(city, sample_frac=0.1, seed=42):\n",
    "    \"\"\"Load validation data: sample from days 61-75 unmasked data\"\"\"\n",
    "    path = f\"{DATA_DIR}/city_{city}_challengedata.csv\"\n",
    "    test_parts = []\n",
    "    all_indices = []\n",
    "    \n",
    "    chunk_counter = 0\n",
    "    for chunk in pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE):\n",
    "        mask = (chunk[\"d\"] >= TEST_DAY_MIN) & (chunk[\"d\"] <= TEST_DAY_MAX) & (chunk[\"x\"] != MASK_VALUE)\n",
    "        valid_chunk = chunk[mask].copy()\n",
    "        \n",
    "        if not valid_chunk.empty:\n",
    "            # Store global indices\n",
    "            global_indices = valid_chunk.index + chunk_counter * CHUNK_SIZE\n",
    "            valid_chunk['global_idx'] = global_indices\n",
    "            test_parts.append(valid_chunk)\n",
    "            all_indices.extend(global_indices)\n",
    "        \n",
    "        chunk_counter += 1\n",
    "    \n",
    "    if not test_parts:\n",
    "        print(\"No unmasked test data found!\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), []\n",
    "    \n",
    "    test_df = pd.concat(test_parts, ignore_index=True)\n",
    "    print(f\"Unmasked test data (days {TEST_DAY_MIN}-{TEST_DAY_MAX}): {len(test_df)} rows\")\n",
    "\n",
    "    # Sample for validation\n",
    "    np.random.seed(seed)\n",
    "    sampled_indices = np.random.choice(len(test_df), size=int(len(test_df) * sample_frac), replace=False)\n",
    "    \n",
    "    validation_df = test_df.iloc[sampled_indices].copy()\n",
    "    validation_global_indices = validation_df['global_idx'].tolist()\n",
    "    \n",
    "    # Create ground truth for validation\n",
    "    validation_gt = validation_df[[\"uid\", \"d\", \"t\", \"x\", \"y\"]].copy()\n",
    "    validation_gt = validation_gt.rename(columns={\"x\": \"x_orig\", \"y\": \"y_orig\"})\n",
    "    \n",
    "    # Mask the validation samples\n",
    "    validation_df[\"x\"] = MASK_VALUE\n",
    "    validation_df[\"y\"] = MASK_VALUE\n",
    "    \n",
    "    # Create remaining training data (unmasked test data not used for validation)\n",
    "    remaining_indices = set(range(len(test_df))) - set(sampled_indices)\n",
    "    remaining_df = test_df.iloc[list(remaining_indices)].copy()\n",
    "    \n",
    "    # Combine remaining data as additional test data for prediction\n",
    "    full_test_df = pd.concat([remaining_df, validation_df], ignore_index=True)\n",
    "    full_test_df = full_test_df.sort_values([\"uid\", \"d\", \"t\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Validation samples: {len(validation_df)} rows\")\n",
    "    print(f\"Additional training from test period: {len(remaining_df)} rows\")\n",
    "    \n",
    "    return full_test_df, validation_gt[[\"uid\", \"d\", \"t\", \"x_orig\", \"y_orig\"]], validation_global_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f58bef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.458228Z",
     "iopub.status.busy": "2025-07-29T15:59:30.457871Z",
     "iopub.status.idle": "2025-07-29T15:59:30.465989Z",
     "shell.execute_reply": "2025-07-29T15:59:30.465035Z"
    },
    "papermill": {
     "duration": 0.013704,
     "end_time": "2025-07-29T15:59:30.467562",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.453858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_prediction(model, test_df, user_trajs):\n",
    "    pred_df = test_df[[\"uid\", \"d\", \"t\"]].copy()\n",
    "    pred_df[\"x_pred\"] = 0\n",
    "    pred_df[\"y_pred\"] = 0\n",
    "\n",
    "    for uid, group in tqdm(test_df.groupby(\"uid\"), desc=\"Predicting\"):\n",
    "        if uid in user_trajs and user_trajs[uid]:\n",
    "            last_known = user_trajs[uid][-1][0]\n",
    "        else:\n",
    "            user_known = group[group[\"x\"] != MASK_VALUE]\n",
    "            if not user_known.empty:\n",
    "                last_known = tuple(user_known[[\"x\", \"y\"]].iloc[0])\n",
    "            else:\n",
    "                last_known = (0, 0)\n",
    "\n",
    "        current_loc = last_known\n",
    "        preds = []\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            if row[\"x\"] == MASK_VALUE:\n",
    "                pred = model.predict(uid, row[\"d\"], row[\"t\"], current_loc)\n",
    "            else:\n",
    "                pred = (row[\"x\"], row[\"y\"])\n",
    "            preds.append(pred)\n",
    "            current_loc = pred\n",
    "\n",
    "        idxs = group.index\n",
    "        pred_df.loc[idxs, \"x_pred\"] = [p[0] for p in preds]\n",
    "        pred_df.loc[idxs, \"y_pred\"] = [p[1] for p in preds]\n",
    "\n",
    "    return pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17be842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:59:30.475254Z",
     "iopub.status.busy": "2025-07-29T15:59:30.474918Z",
     "iopub.status.idle": "2025-07-29T16:03:04.348009Z",
     "shell.execute_reply": "2025-07-29T16:03:04.346969Z"
    },
    "papermill": {
     "duration": 213.878862,
     "end_time": "2025-07-29T16:03:04.349523",
     "exception": false,
     "start_time": "2025-07-29T15:59:30.470661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CITY A EVALUATION\n",
      "==================================================\n",
      "Loading and processing data...\n",
      "Processing chunk 1...\n",
      "Processing chunk 2...\n",
      "Processing chunk 3...\n",
      "Processing chunk 4...\n",
      "Processing chunk 5...\n",
      "Processing chunk 6...\n",
      "Processing chunk 7...\n",
      "Processing chunk 8...\n",
      "Processing chunk 9...\n",
      "Processing chunk 10...\n",
      "Processing chunk 11...\n",
      "Processing chunk 12...\n",
      "Processing chunk 13...\n",
      "Processing chunk 14...\n",
      "Processing chunk 15...\n",
      "Processing chunk 16...\n",
      "Processing chunk 17...\n",
      "Processing chunk 18...\n",
      "Processing chunk 19...\n",
      "Processing chunk 20...\n",
      "Processing chunk 21...\n",
      "Processing chunk 22...\n",
      "Processing chunk 23...\n",
      "Processing chunk 24...\n",
      "Processing chunk 25...\n",
      "Processing chunk 26...\n",
      "Processing chunk 27...\n",
      "Processing chunk 28...\n",
      "Processing chunk 29...\n",
      "Processing chunk 30...\n",
      "Processing chunk 31...\n",
      "Processing chunk 32...\n",
      "Processing chunk 33...\n",
      "Processing chunk 34...\n",
      "Processing chunk 35...\n",
      "Processing chunk 36...\n",
      "Processing chunk 37...\n",
      "Processing chunk 38...\n",
      "Processing chunk 39...\n",
      "Processing chunk 40...\n",
      "Processing chunk 41...\n",
      "Processing chunk 42...\n",
      "Processing chunk 43...\n",
      "Processing chunk 44...\n",
      "Processing chunk 45...\n",
      "Processing chunk 46...\n",
      "Processing chunk 47...\n",
      "Processing chunk 48...\n",
      "Processing chunk 49...\n",
      "Processing chunk 50...\n",
      "Processing chunk 51...\n",
      "Processing chunk 52...\n",
      "Processing chunk 53...\n",
      "Processing chunk 54...\n",
      "Processing chunk 55...\n",
      "Processing chunk 56...\n",
      "Processing chunk 57...\n",
      "Processing chunk 58...\n",
      "Processing chunk 59...\n",
      "Processing chunk 60...\n",
      "Processing chunk 61...\n",
      "Processing chunk 62...\n",
      "Processing chunk 63...\n",
      "Processing chunk 64...\n",
      "Processing chunk 65...\n",
      "Processing chunk 66...\n",
      "Processing chunk 67...\n",
      "Processing chunk 68...\n",
      "Processing chunk 69...\n",
      "Processing chunk 70...\n",
      "Processing chunk 71...\n",
      "Processing chunk 72...\n",
      "Processing chunk 73...\n",
      "Processing chunk 74...\n",
      "Processing chunk 75...\n",
      "Processing chunk 76...\n",
      "Processing chunk 77...\n",
      "Processing chunk 78...\n",
      "Processing chunk 79...\n",
      "Processing chunk 80...\n",
      "Processing chunk 81...\n",
      "Processing chunk 82...\n",
      "Processing chunk 83...\n",
      "Processing chunk 84...\n",
      "Processing chunk 85...\n",
      "Processing chunk 86...\n",
      "Processing chunk 87...\n",
      "Processing chunk 88...\n",
      "Processing chunk 89...\n",
      "Processing chunk 90...\n",
      "Processing chunk 91...\n",
      "Processing chunk 92...\n",
      "Processing chunk 93...\n",
      "Processing chunk 94...\n",
      "Processing chunk 95...\n",
      "Processing chunk 96...\n",
      "Processing chunk 97...\n",
      "Processing chunk 98...\n",
      "Processing chunk 99...\n",
      "Processing chunk 100...\n",
      "Processing chunk 101...\n",
      "Processing chunk 102...\n",
      "Processing chunk 103...\n",
      "Processing chunk 104...\n",
      "Processing chunk 105...\n",
      "Processing chunk 106...\n",
      "Processing chunk 107...\n",
      "Processing chunk 108...\n",
      "Processing chunk 109...\n",
      "Processing chunk 110...\n",
      "Processing chunk 111...\n",
      "Processing chunk 112...\n",
      "Processing chunk 113...\n",
      "Processing chunk 114...\n",
      "Processing chunk 115...\n",
      "Processing chunk 116...\n",
      "Processing chunk 117...\n",
      "Processing chunk 118...\n",
      "Processing chunk 119...\n",
      "Processing chunk 120...\n",
      "Processing chunk 121...\n",
      "Processing chunk 122...\n",
      "Processing chunk 123...\n",
      "Processing chunk 124...\n",
      "Processing chunk 125...\n",
      "Processing chunk 126...\n",
      "Processing chunk 127...\n",
      "Processing chunk 128...\n",
      "Processing chunk 129...\n",
      "Processing chunk 130...\n",
      "Processing chunk 131...\n",
      "Processing chunk 132...\n",
      "Processing chunk 133...\n",
      "Processing chunk 134...\n",
      "Processing chunk 135...\n",
      "Processing chunk 136...\n",
      "Processing chunk 137...\n",
      "Processing chunk 138...\n",
      "Processing chunk 139...\n",
      "Processing chunk 140...\n",
      "Processing chunk 141...\n",
      "Processing chunk 142...\n",
      "Processing chunk 143...\n",
      "Processing chunk 144...\n",
      "Processing chunk 145...\n",
      "Processing chunk 146...\n",
      "Processing chunk 147...\n",
      "Processing chunk 148...\n",
      "Processing chunk 149...\n",
      "Processing chunk 150...\n",
      "Processing chunk 151...\n",
      "Processing chunk 152...\n",
      "Processing chunk 153...\n",
      "Processing chunk 154...\n",
      "Processing chunk 155...\n",
      "Processing chunk 156...\n",
      "Processing chunk 157...\n",
      "Processing chunk 158...\n",
      "Processing chunk 159...\n",
      "Processing chunk 160...\n",
      "Processing chunk 161...\n",
      "Processing chunk 162...\n",
      "Processing chunk 163...\n",
      "Processing chunk 164...\n",
      "Processing chunk 165...\n",
      "Processing chunk 166...\n",
      "Processing chunk 167...\n",
      "Processing chunk 168...\n",
      "Processing chunk 169...\n",
      "Processing chunk 170...\n",
      "Processing chunk 171...\n",
      "Processing chunk 172...\n",
      "Processing chunk 173...\n",
      "Processing chunk 174...\n",
      "Processing chunk 175...\n",
      "Training data loaded: 86722027 points\n",
      "Test data collected for 3000 users\n",
      "Building models and making predictions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d35d3d22fb84bb0a79ebd738dd645ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing users:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 users, 12501 predictions so far\n",
      "Processed 200 users, 23993 predictions so far\n",
      "Processed 300 users, 35942 predictions so far\n",
      "Processed 400 users, 47241 predictions so far\n",
      "Processed 500 users, 58388 predictions so far\n",
      "Processed 600 users, 69427 predictions so far\n",
      "Processed 700 users, 81050 predictions so far\n",
      "Processed 800 users, 91196 predictions so far\n",
      "Processed 900 users, 102386 predictions so far\n",
      "Processed 1000 users, 113496 predictions so far\n",
      "Processed 1100 users, 123799 predictions so far\n",
      "Processed 1200 users, 134443 predictions so far\n",
      "Processed 1300 users, 146175 predictions so far\n",
      "Processed 1400 users, 156650 predictions so far\n",
      "Processed 1500 users, 166790 predictions so far\n",
      "Processed 1600 users, 177004 predictions so far\n",
      "Processed 1700 users, 187614 predictions so far\n",
      "Processed 1800 users, 198128 predictions so far\n",
      "Processed 1900 users, 208179 predictions so far\n",
      "Processed 2000 users, 217728 predictions so far\n",
      "Processed 2100 users, 227268 predictions so far\n",
      "Processed 2200 users, 237442 predictions so far\n",
      "Processed 2300 users, 247446 predictions so far\n",
      "Processed 2400 users, 257110 predictions so far\n",
      "Processed 2500 users, 266427 predictions so far\n",
      "Processed 2600 users, 276256 predictions so far\n",
      "Processed 2700 users, 286609 predictions so far\n",
      "Processed 2800 users, 296486 predictions so far\n",
      "Processed 2900 users, 307400 predictions so far\n",
      "Processed 3000 users, 320391 predictions so far\n",
      "Total predictions: 320391\n",
      "Predictions saved to city_A_ttknn_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Updated configuration with improved parameters\n",
    "TTKNN_VALUES = {\n",
    "    \"TAU\": 0,      # Reduced threshold for more locations\n",
    "    \"DELTA\": 30,   # 30 minutes\n",
    "    \"M\": 3,        # Look ahead 3 segments (1.5 hours)\n",
    "    \"K\": 2,        # Consider more candidates\n",
    "}\n",
    "\n",
    "# Use only the first configuration to save memory\n",
    "DISTANCE_TYPE = 'euclidean'\n",
    "FREQ_WEIGHT = 0.5\n",
    "\n",
    "for city in CITIES:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"CITY {city} EVALUATION\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Path to the data file\n",
    "    path = f\"{DATA_DIR}/city_{city}_challengedata.csv\"\n",
    "    \n",
    "    # Process all data in chunks, but collect by user in memory (like in flat_TT_KNN(freq).ipynb)\n",
    "    print(\"Loading and processing data...\")\n",
    "    \n",
    "    # Store all unmasked (training) and masked (test) data by user\n",
    "    user_train_data = defaultdict(list)\n",
    "    user_test_data = defaultdict(list)\n",
    "    \n",
    "    # Process in chunks but collect all data for all users\n",
    "    chunk_count = 0\n",
    "    for chunk in pd.read_csv(path, usecols=COLUMNS, dtype=DTYPES, chunksize=CHUNK_SIZE):\n",
    "        chunk_count += 1\n",
    "        print(f\"Processing chunk {chunk_count}...\")\n",
    "        \n",
    "        # Split into train and test based on masked status\n",
    "        train_chunk = chunk[chunk[\"x\"] != MASK_VALUE]\n",
    "        test_chunk = chunk[chunk[\"x\"] == MASK_VALUE]\n",
    "        \n",
    "        # Process training data and collect by user\n",
    "        for uid, group in train_chunk.groupby(\"uid\"):\n",
    "            locs = list(zip(group[\"x\"], group[\"y\"]))\n",
    "            times = list(zip(group[\"d\"], group[\"t\"]))\n",
    "            user_train_data[uid].extend(zip(locs, times))\n",
    "        \n",
    "        # Collect test data by user\n",
    "        for uid, group in test_chunk.groupby(\"uid\"):\n",
    "            user_test_data[uid].append(group)\n",
    "    \n",
    "    print(f\"Training data loaded: {sum(len(traj) for traj in user_train_data.values())} points\")\n",
    "    print(f\"Test data collected for {len(user_test_data)} users\")\n",
    "    \n",
    "    # Initialize empty list for all predictions\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Process users in batch (process model building and prediction for each user)\n",
    "    print(\"Building models and making predictions...\")\n",
    "    \n",
    "    # Process each user with test data to predict\n",
    "    user_count = 0\n",
    "    for uid in tqdm(user_test_data.keys(), desc=\"Processing users\"):\n",
    "        user_count += 1\n",
    "        \n",
    "        # Skip users with no test data (shouldn't happen since we're iterating over test data keys)\n",
    "        if len(user_test_data[uid]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Combine all test data chunks for this user\n",
    "        test_df = pd.concat(user_test_data[uid], ignore_index=True)\n",
    "        \n",
    "        # Build model for this user if they have training data\n",
    "        if uid in user_train_data and user_train_data[uid]:\n",
    "            # Format training data and build indices for this user\n",
    "            formatted = [(d, t, x, y) for (x, y), (d, t) in user_train_data[uid]]\n",
    "            user_index, user_freq_index = build_flat_TT_index(\n",
    "                formatted,\n",
    "                tau=TTKNN_VALUES[\"TAU\"],\n",
    "                delta=TTKNN_VALUES[\"DELTA\"]\n",
    "            )\n",
    "            \n",
    "            # Get last known location\n",
    "            last_known = user_train_data[uid][-1][0]\n",
    "        else:\n",
    "            # No training data, initialize empty indices and default location\n",
    "            user_index = defaultdict(lambda: defaultdict(list))\n",
    "            user_freq_index = defaultdict(lambda: defaultdict(Counter))\n",
    "            last_known = (0, 0)\n",
    "        \n",
    "        # Make predictions for this user\n",
    "        current_loc = last_known\n",
    "        \n",
    "        # Sort test data by day and time to ensure sequential prediction\n",
    "        test_rows_sorted = test_df.sort_values([\"d\", \"t\"])\n",
    "        \n",
    "        # Predict each masked location\n",
    "        for _, row in test_rows_sorted.iterrows():\n",
    "            d, t = row[\"d\"], row[\"t\"]\n",
    "            \n",
    "            # Predict using this user's model\n",
    "            pred = predict_next_location_flat(\n",
    "                user_index, \n",
    "                user_freq_index,\n",
    "                d, t, current_loc,\n",
    "                M=TTKNN_VALUES[\"M\"],\n",
    "                K=TTKNN_VALUES[\"K\"],\n",
    "                delta=TTKNN_VALUES[\"DELTA\"],\n",
    "                distance_type=DISTANCE_TYPE,\n",
    "                freq_weight=FREQ_WEIGHT\n",
    "            )\n",
    "            \n",
    "            # Add prediction to results\n",
    "            all_predictions.append({\n",
    "                \"uid\": uid,\n",
    "                \"d\": d,\n",
    "                \"t\": t,\n",
    "                \"x\": pred[0],\n",
    "                \"y\": pred[1]\n",
    "            })\n",
    "            \n",
    "            # Update current location for next prediction\n",
    "            current_loc = pred\n",
    "        \n",
    "        # Clear memory before next user\n",
    "        if user_count % 100 == 0:\n",
    "            print(f\"Processed {user_count} users, {len(all_predictions)} predictions so far\")\n",
    "        \n",
    "        # Clear memory for this user\n",
    "        del test_df, user_index, user_freq_index\n",
    "    \n",
    "    # Convert all predictions to dataframe\n",
    "    if all_predictions:\n",
    "        pred_df = pd.DataFrame(all_predictions)\n",
    "        print(f\"Total predictions: {len(pred_df)}\")\n",
    "        \n",
    "        # Save predictions in same format as input\n",
    "        output_file = f\"city_{city}_ttknn_predictions.csv\"\n",
    "        pred_df.to_csv(output_file, index=False)\n",
    "        print(f\"Predictions saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No predictions made!\")\n",
    "\n",
    "# Metrics calculation code is commented out (already done in existing code)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7587200,
     "sourceId": 12055345,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 235.984729,
   "end_time": "2025-07-29T16:03:08.087315",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-29T15:59:12.102586",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1e569c6004c74ed2ab77144a168ca89b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_629046b607ef454a932b60c5bc080713",
       "placeholder": "​",
       "style": "IPY_MODEL_44966849e4904127969c433af395eda5",
       "tabbable": null,
       "tooltip": null,
       "value": "Processing users: 100%"
      }
     },
     "20766166dbb943028bfda606ae273a6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28f3a78fb4a4481c9fb8d909ae6a22c7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "378430408fb04aadbc2fd34a1215e6c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "44966849e4904127969c433af395eda5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5801b9ee6501446f839e73884e985796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28f3a78fb4a4481c9fb8d909ae6a22c7",
       "max": 3000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_378430408fb04aadbc2fd34a1215e6c1",
       "tabbable": null,
       "tooltip": null,
       "value": 3000.0
      }
     },
     "629046b607ef454a932b60c5bc080713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c93bed3eed6480489fd5e203665796e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73f289de976c4859b6de73fd1a13b579",
       "placeholder": "​",
       "style": "IPY_MODEL_eb999f77e45e44888477c395720e962d",
       "tabbable": null,
       "tooltip": null,
       "value": " 3000/3000 [00:25&lt;00:00, 122.06it/s]"
      }
     },
     "6d35d3d22fb84bb0a79ebd738dd645ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1e569c6004c74ed2ab77144a168ca89b",
        "IPY_MODEL_5801b9ee6501446f839e73884e985796",
        "IPY_MODEL_6c93bed3eed6480489fd5e203665796e"
       ],
       "layout": "IPY_MODEL_20766166dbb943028bfda606ae273a6b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "73f289de976c4859b6de73fd1a13b579": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb999f77e45e44888477c395720e962d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
